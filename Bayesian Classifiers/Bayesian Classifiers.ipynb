{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,191);\">Bayesian Classifiers</h1>\n",
    "<br/>\n",
    "<p>\n",
    "    In this tutorial we will explore a machine learning algorithm used for classification problems: <strong style=\"color:rgb(0,120,191);\">the Bayes classifier</strong> and its variants, <strong style=\"color:rgb(0,120,191);\">the Plug-In and Naïve Bayes classifiers</strong>.\n",
    "    We will give proper definition of each of these and apply the algorithms on a toy dataset, and also on the well-known iris dataset.\n",
    "</p>\n",
    "<p> \n",
    "    <strong>Prerequisites</strong>:<br/> knowledge of following machine learning concepts: feature, label, training data, validation data, accuracy, maximum likelihood estimation \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"color:rgb(0,120,191);\">1) What is classification?</h1>\n",
    "<h2>a) The classification problem</h2>\n",
    "<p>\n",
    "    We have n observations x<sub>1</sub>, ..., x<sub>n</sub> in R<sup>d</sup> and we would like to assign each of these vectors into a class  (i.e a category) among K classes y<sub>1</sub>, y<sub>2</sub>, ..., y<sub>k</sub>. <br/>\n",
    "If K=2, we talk about <strong>binary classification</strong>, for K &ge; 3 we talk about <strong>multiclass classification.</strong>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    Let f be the function which maps input vector x to a class y:  &nbsp;    <strong>y = f(x)</strong> <br/>\n",
    "    <ol>\n",
    "        We need to\n",
    "        <li>\n",
    "             Define what function we're going to use for this mapping </li>\n",
    "        <li>Learn the parameters of this function by using pairs of labeled points (x<sub>i</sub>,y<sub>i</sub>) i=1,...,n</li>\n",
    "        </ol>\n",
    "    \n",
    "</p>\n",
    "\n",
    "<h2>b) How can we measure the quality of a classifier?</h2>\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        The prediction accuracy is the probability of classifying correctly the data: P( f(x) = y ). We want to maximize this!       </li>\n",
    "    <li>The prediction error is the probability of misclassifying the data: P( f(x) &#x2260; y ). We want to minimize this!</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "    To calculate these probabilities, we need to make an important hypothesis here: <br/>\n",
    "    \n",
    "   Our observed data (x<sub>i</sub>,y<sub>i</sub>)  i=1,..., n are <strong>independant and identically distributed (IID)</strong> via a distribution D (that we dont know).<br/>\n",
    "   \"Independent\" means that the observation x<sub>i</sub> does not depend on the observation x<sub>j</sub> for any i &ne; j. <br/>\n",
    "   \"Identically distributed\" means that the samples come from the same distribution. <br/><br/>\n",
    "   <strong>NB: Through the statistical learning theory</strong>, we know that <strong>performing well on the training set ensures a good generalization on the testing set!</strong> (where we only get to see the x<sub>i</sub>)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><h1 style=\"color:rgb(0,120,191);\">2) What is the Bayes classifier?</h1>\n",
    "<p>\n",
    "    Let's define the optimal classifier as the classifier which minimizes the prediction error. <br/>\n",
    "    If we get the data IID from some underlying distribution D, and then for every single vector x, we predict the label y to be the most probable label according to that distribution, then the prediction error will be minimized and <strong style=\"color:rgb(0,120,191);\">this classifier is the Bayes classifier!</strong>\n",
    "</p>\n",
    "<p>\n",
    "    But of course, we don't know the distribution D, so we will have to approximate it, and <strong>therefore we will no longer be able to say the classifier is optimal!</strong>\n",
    "</p>\n",
    "<p>\n",
    "  So what we want, is to maximize the probability P(y|x), &nbsp;&nbsp;\n",
    "  Let's recall Bayes rule: <br/> &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;\n",
    "  P(y|x) = P(x|y) P(y)  /  P(x) &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;(E1) \n",
    "  <ul>\n",
    "    <li>P(y|x) is called the <strong>posterior</strong>, it is the posterior belief of the unknown class y given the observation x</li>\n",
    "    <li>P(x|y) is the <strong>class conditionnal distribution</strong> (also called the <strong>likelihood</strong> of the data given the class), it is the class specific distribution on vector x given that it belongs to class y</li>\n",
    "    <li>P(y) is the class <strong>prior</strong>, it's the a priori assumption we make on the distribution of the class</li> \n",
    "    <li>P(x) is called the <strong>evidence</strong>, it is a normalizing constant</li>      \n",
    "  </ul>\n",
    "So we want to maximize the probability of the posterior:   we're interested in finding the class y which is the most probable, so we can write this: <br/>    \n",
    "&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; argmax<sub>y</sub> P(y|x) &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; <=>  &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; argmax<sub>y</sub> P(x|y) P(y)  /  P(x)  &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; <br/><br/>\n",
    "    Now, notice that the denominator P(x) doesn't depend on y, we can just get rid of it and write: <br/><br/>\n",
    "    &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;  <strong>f<sub>opt</sub>(x) = argmax<sub>y</sub>\n",
    "    P(x|y) P(y) &nbsp;&nbsp; &nbsp;&nbsp; (E2) </strong>  &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; \n",
    "    <strong style=\"color:rgb(0,120,191);\">where f<sub>opt</sub> is the Bayes classifier</strong>\n",
    "</p>\n",
    "<p>\n",
    "    <strong>Remember that we don't know any of these distributions so we're going to approximate them!</strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,191);\">3) Example with Gaussian class conditional densities</h1>\n",
    "<p>\n",
    "    Let's consider the following example: <br/>\n",
    "    <ul>\n",
    "        We get to observe scalar data (x &isin; &#8476;) and the corresponding label is either 0 or 1  (y &isin; {0, 1}). So it'a binary classification problem! <br/>\n",
    "        Let's assume that <strong>we know the exact distribution of the (x, y) pairs</strong> in our dataset and that it's defined as follows: \n",
    "        <br/><br/>\n",
    "        <li>The class prior for label 0 is &pi;<sub>0</sub> and the class prior for label 1 is &pi;<sub>1</sub></li>\n",
    "        <li>The class conditionnal densities for classes 0 and 1 are univariate gaussians p<sub>0</sub>(x) &#8765; N(µ<sub>0</sub>, &sigma;<sub>0</sub><sup>2</sup>) &nbsp;&nbsp; and  &nbsp;&nbsp; p<sub>1</sub>(x) &#8765; N(µ<sub>1</sub>, &sigma;<sub>1</sub><sup>2</sup>) respectively.\n",
    "    </ul>\n",
    "</p>\n",
    "<p>\n",
    "    Let's recall the expression of the probability density of a univariate gaussian &#8765; f(x|µ, &sigma;<sup>2</sup>) \n",
    "    <img src=\"univariateGaussian.JPG\" alt=\"P(x<sub>j</sub>|y) = (1/&sigma;&radic;(2&pi;))exp[-(x-µ)<sup>2</sup>/(2&sigma;<sup>2</sup>)]\">\n",
    "</p>\n",
    "<p> The Bayes classifier assigns to each sample, the most probable class:\n",
    "    <strong>f<sub>opt</sub>(x) = argmax<sub>y</sub>\n",
    "    P(x|y) x P(y) &nbsp;&nbsp; &nbsp;&nbsp; (E2) </strong> <br/><br/>\n",
    "    So for each data x, if p<sub>1</sub>(x)  &pi;<sub>1</sub> > p<sub>0</sub>(x) &pi;<sub>0</sub>, &nbsp; &nbsp; then class 1 will be assigned, otherwise, class 0 will be assigned!\n",
    "    <br/><br/>\n",
    "   Let's draw some graph illustrating this! <br/><br/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "name": "class 0",
         "type": "scatter",
         "uid": "99b03f2f-cd79-4f52-b1e2-a53325315262",
         "x": [
          -5,
          -4.949748743718593,
          -4.899497487437186,
          -4.849246231155779,
          -4.798994974874372,
          -4.748743718592965,
          -4.698492462311558,
          -4.648241206030151,
          -4.597989949748744,
          -4.547738693467337,
          -4.49748743718593,
          -4.447236180904523,
          -4.396984924623116,
          -4.346733668341709,
          -4.296482412060302,
          -4.2462311557788945,
          -4.1959798994974875,
          -4.1457286432160805,
          -4.0954773869346734,
          -4.045226130653266,
          -3.9949748743718594,
          -3.9447236180904524,
          -3.8944723618090453,
          -3.8442211055276383,
          -3.7939698492462313,
          -3.7437185929648242,
          -3.693467336683417,
          -3.64321608040201,
          -3.592964824120603,
          -3.542713567839196,
          -3.492462311557789,
          -3.442211055276382,
          -3.391959798994975,
          -3.341708542713568,
          -3.291457286432161,
          -3.241206030150754,
          -3.190954773869347,
          -3.14070351758794,
          -3.090452261306533,
          -3.040201005025126,
          -2.9899497487437183,
          -2.9396984924623113,
          -2.8894472361809043,
          -2.8391959798994972,
          -2.78894472361809,
          -2.738693467336683,
          -2.688442211055276,
          -2.638190954773869,
          -2.587939698492462,
          -2.537688442211055,
          -2.487437185929648,
          -2.437185929648241,
          -2.386934673366834,
          -2.336683417085427,
          -2.28643216080402,
          -2.236180904522613,
          -2.185929648241206,
          -2.135678391959799,
          -2.0854271356783918,
          -2.0351758793969847,
          -1.9849246231155777,
          -1.9346733668341707,
          -1.8844221105527637,
          -1.8341708542713566,
          -1.7839195979899496,
          -1.7336683417085426,
          -1.6834170854271355,
          -1.6331658291457285,
          -1.5829145728643215,
          -1.5326633165829144,
          -1.4824120603015074,
          -1.4321608040201004,
          -1.3819095477386933,
          -1.3316582914572863,
          -1.2814070351758793,
          -1.2311557788944723,
          -1.1809045226130652,
          -1.1306532663316582,
          -1.0804020100502512,
          -1.0301507537688441,
          -0.9798994974874367,
          -0.9296482412060296,
          -0.8793969849246226,
          -0.8291457286432156,
          -0.7788944723618085,
          -0.7286432160804015,
          -0.6783919597989945,
          -0.6281407035175874,
          -0.5778894472361804,
          -0.5276381909547734,
          -0.47738693467336635,
          -0.4271356783919593,
          -0.3768844221105523,
          -0.32663316582914526,
          -0.2763819095477382,
          -0.2261306532663312,
          -0.17587939698492416,
          -0.12562814070351713,
          -0.0753768844221101,
          -0.02512562814070307,
          0.02512562814070396,
          0.07537688442211099,
          0.12562814070351802,
          0.17587939698492505,
          0.22613065326633208,
          0.2763819095477391,
          0.32663316582914614,
          0.3768844221105532,
          0.4271356783919602,
          0.47738693467336724,
          0.5276381909547743,
          0.5778894472361813,
          0.6281407035175883,
          0.6783919597989954,
          0.7286432160804024,
          0.7788944723618094,
          0.8291457286432165,
          0.8793969849246235,
          0.9296482412060305,
          0.9798994974874375,
          1.0301507537688446,
          1.0804020100502516,
          1.1306532663316586,
          1.1809045226130657,
          1.2311557788944727,
          1.2814070351758797,
          1.3316582914572868,
          1.3819095477386938,
          1.4321608040201008,
          1.4824120603015079,
          1.5326633165829149,
          1.582914572864322,
          1.633165829145729,
          1.683417085427136,
          1.733668341708543,
          1.78391959798995,
          1.834170854271357,
          1.884422110552764,
          1.9346733668341711,
          1.9849246231155782,
          2.035175879396985,
          2.085427135678392,
          2.1356783919597992,
          2.1859296482412063,
          2.2361809045226133,
          2.2864321608040203,
          2.3366834170854274,
          2.3869346733668344,
          2.4371859296482414,
          2.4874371859296485,
          2.5376884422110555,
          2.5879396984924625,
          2.6381909547738696,
          2.6884422110552766,
          2.7386934673366836,
          2.7889447236180906,
          2.8391959798994977,
          2.8894472361809047,
          2.9396984924623117,
          2.9899497487437188,
          3.0402010050251267,
          3.090452261306533,
          3.1407035175879408,
          3.190954773869347,
          3.241206030150755,
          3.291457286432161,
          3.341708542713569,
          3.391959798994975,
          3.442211055276383,
          3.492462311557789,
          3.542713567839197,
          3.592964824120603,
          3.643216080402011,
          3.693467336683417,
          3.743718592964825,
          3.7939698492462313,
          3.844221105527639,
          3.8944723618090453,
          3.9447236180904532,
          3.9949748743718594,
          4.045226130653267,
          4.0954773869346734,
          4.145728643216081,
          4.1959798994974875,
          4.246231155778895,
          4.296482412060302,
          4.3467336683417095,
          4.396984924623116,
          4.4472361809045236,
          4.49748743718593,
          4.547738693467338,
          4.597989949748744,
          4.648241206030152,
          4.698492462311558,
          4.748743718592966,
          4.798994974874372,
          4.84924623115578,
          4.899497487437186,
          4.949748743718594,
          5
         ],
         "y": [
          0.0010281859975274045,
          0.0011490142345814737,
          0.0012826014351765447,
          0.0014301138833504145,
          0.0015928031745197717,
          0.001772010092479435,
          0.0019691684016190742,
          0.0021858085177893375,
          0.0024235610181197915,
          0.0026841599469854325,
          0.002969445872272179,
          0.0032813686431437078,
          0.003621989797704343,
          0.003993484566330498,
          0.004398143414053857,
          0.0048383730632731185,
          0.005316696936299597,
          0.005835754955858536,
          0.006398302640726588,
          0.00700720943324149,
          0.00766545619552614,
          0.008376131811979125,
          0.009142428836948503,
          0.009967638128573117,
          0.010855142412591027,
          0.011808408723517277,
          0.012830979675018051,
          0.01392646351658327,
          0.015098522939745217,
          0.016350862604119498,
          0.017687215361459157,
          0.01911132716470631,
          0.020626940658680502,
          0.02223777745952852,
          0.023947519141336953,
          0.025759786960320295,
          0.0276781203596774,
          0.029705954311478065,
          0.03184659556570474,
          0.0341031978907266,
          0.036478736403905504,
          0.03897598110559366,
          0.041597469744342266,
          0.044345480155541996,
          0.04722200222980392,
          0.050228709680990705,
          0.05336693179675048,
          0.056637625366509174,
          0.06004134699296218,
          0.06357822600299094,
          0.06724793818243621,
          0.07104968056611516,
          0.07498214751970457,
          0.07904350835347554,
          0.08323138670920636,
          0.08754284196079627,
          0.09197435286603677,
          0.09652180370158164,
          0.1011804731053182,
          0.10594502584003766,
          0.11080950767951012,
          0.11576734360280043,
          0.12081133946494639,
          0.12593368729203372,
          0.1311259743263341,
          0.13637919592265363,
          0.14168377237052615,
          0.14702956968856742,
          0.152405924407396,
          0.15780167232626957,
          0.16320518119625044,
          0.168604387249589,
          0.17398683546141247,
          0.1793397233960552,
          0.18464994845680777,
          0.18990415832484223,
          0.19508880434095327,
          0.20019019755288744,
          0.20519456712177644,
          0.2100881207538881,
          0.21485710679889372,
          0.21948787763343955,
          0.22396695392930252,
          0.22828108938906622,
          0.2324173355193272,
          0.23636310600212554,
          0.24010624021977184,
          0.24363506548663535,
          0.24693845754386423,
          0.25000589887946556,
          0.2528275344466883,
          0.25539422436817777,
          0.2576975932318133,
          0.2597300756063714,
          0.2614849574309861,
          0.26295641296159,
          0.2641395369898463,
          0.2650303720852233,
          0.2656259306484852,
          0.26592421160461105,
          0.26592421160461105,
          0.2656259306484852,
          0.2650303720852233,
          0.2641395369898463,
          0.26295641296159,
          0.26148495743098604,
          0.25973007560637135,
          0.2576975932318133,
          0.25539422436817777,
          0.25282753444668826,
          0.2500058988794655,
          0.24693845754386418,
          0.2436350654866353,
          0.24010624021977178,
          0.23636310600212548,
          0.2324173355193271,
          0.22828108938906613,
          0.2239669539293024,
          0.21948787763343947,
          0.21485710679889364,
          0.21008812075388808,
          0.20519456712177636,
          0.20019019755288736,
          0.19508880434095321,
          0.18990415832484217,
          0.1846499484568077,
          0.17933972339605517,
          0.17398683546141241,
          0.16860438724958896,
          0.16320518119625038,
          0.15780167232626952,
          0.15240592440739598,
          0.14702956968856737,
          0.1416837723705261,
          0.1363791959226536,
          0.13112597432633408,
          0.12593368729203366,
          0.12081133946494632,
          0.11576734360280039,
          0.11080950767951007,
          0.1059450258400376,
          0.10118047310531818,
          0.09652180370158159,
          0.09197435286603671,
          0.08754284196079623,
          0.08323138670920635,
          0.07904350835347551,
          0.07498214751970454,
          0.07104968056611513,
          0.06724793818243618,
          0.0635782260029909,
          0.06004134699296216,
          0.05663762536650913,
          0.05336693179675045,
          0.05022870968099068,
          0.047222002229803876,
          0.044345480155541975,
          0.04159746974434223,
          0.038975981105593624,
          0.036478736403905476,
          0.034103197890726564,
          0.03184659556570474,
          0.029705954311478027,
          0.0276781203596774,
          0.025759786960320264,
          0.023947519141336953,
          0.022237777459528478,
          0.020626940658680502,
          0.019111327164706288,
          0.017687215361459157,
          0.016350862604119484,
          0.015098522939745217,
          0.013926463516583252,
          0.012830979675018051,
          0.011808408723517261,
          0.010855142412591027,
          0.009967638128573101,
          0.009142428836948503,
          0.008376131811979111,
          0.00766545619552614,
          0.007007209433241478,
          0.006398302640726588,
          0.005835754955858525,
          0.005316696936299597,
          0.0048383730632731055,
          0.004398143414053857,
          0.0039934845663304915,
          0.003621989797704343,
          0.0032813686431437043,
          0.002969445872272179,
          0.0026841599469854278,
          0.0024235610181197915,
          0.002185808517789334,
          0.0019691684016190742,
          0.0017720100924794302,
          0.0015928031745197717,
          0.0014301138833504106,
          0.0012826014351765447,
          0.0011490142345814706,
          0.0010281859975274045
         ]
        },
        {
         "name": "class 1",
         "type": "scatter",
         "uid": "1318b6bc-6260-4bd6-bfbc-4a01a8cbdcf1",
         "x": [
          -5,
          -4.949748743718593,
          -4.899497487437186,
          -4.849246231155779,
          -4.798994974874372,
          -4.748743718592965,
          -4.698492462311558,
          -4.648241206030151,
          -4.597989949748744,
          -4.547738693467337,
          -4.49748743718593,
          -4.447236180904523,
          -4.396984924623116,
          -4.346733668341709,
          -4.296482412060302,
          -4.2462311557788945,
          -4.1959798994974875,
          -4.1457286432160805,
          -4.0954773869346734,
          -4.045226130653266,
          -3.9949748743718594,
          -3.9447236180904524,
          -3.8944723618090453,
          -3.8442211055276383,
          -3.7939698492462313,
          -3.7437185929648242,
          -3.693467336683417,
          -3.64321608040201,
          -3.592964824120603,
          -3.542713567839196,
          -3.492462311557789,
          -3.442211055276382,
          -3.391959798994975,
          -3.341708542713568,
          -3.291457286432161,
          -3.241206030150754,
          -3.190954773869347,
          -3.14070351758794,
          -3.090452261306533,
          -3.040201005025126,
          -2.9899497487437183,
          -2.9396984924623113,
          -2.8894472361809043,
          -2.8391959798994972,
          -2.78894472361809,
          -2.738693467336683,
          -2.688442211055276,
          -2.638190954773869,
          -2.587939698492462,
          -2.537688442211055,
          -2.487437185929648,
          -2.437185929648241,
          -2.386934673366834,
          -2.336683417085427,
          -2.28643216080402,
          -2.236180904522613,
          -2.185929648241206,
          -2.135678391959799,
          -2.0854271356783918,
          -2.0351758793969847,
          -1.9849246231155777,
          -1.9346733668341707,
          -1.8844221105527637,
          -1.8341708542713566,
          -1.7839195979899496,
          -1.7336683417085426,
          -1.6834170854271355,
          -1.6331658291457285,
          -1.5829145728643215,
          -1.5326633165829144,
          -1.4824120603015074,
          -1.4321608040201004,
          -1.3819095477386933,
          -1.3316582914572863,
          -1.2814070351758793,
          -1.2311557788944723,
          -1.1809045226130652,
          -1.1306532663316582,
          -1.0804020100502512,
          -1.0301507537688441,
          -0.9798994974874367,
          -0.9296482412060296,
          -0.8793969849246226,
          -0.8291457286432156,
          -0.7788944723618085,
          -0.7286432160804015,
          -0.6783919597989945,
          -0.6281407035175874,
          -0.5778894472361804,
          -0.5276381909547734,
          -0.47738693467336635,
          -0.4271356783919593,
          -0.3768844221105523,
          -0.32663316582914526,
          -0.2763819095477382,
          -0.2261306532663312,
          -0.17587939698492416,
          -0.12562814070351713,
          -0.0753768844221101,
          -0.02512562814070307,
          0.02512562814070396,
          0.07537688442211099,
          0.12562814070351802,
          0.17587939698492505,
          0.22613065326633208,
          0.2763819095477391,
          0.32663316582914614,
          0.3768844221105532,
          0.4271356783919602,
          0.47738693467336724,
          0.5276381909547743,
          0.5778894472361813,
          0.6281407035175883,
          0.6783919597989954,
          0.7286432160804024,
          0.7788944723618094,
          0.8291457286432165,
          0.8793969849246235,
          0.9296482412060305,
          0.9798994974874375,
          1.0301507537688446,
          1.0804020100502516,
          1.1306532663316586,
          1.1809045226130657,
          1.2311557788944727,
          1.2814070351758797,
          1.3316582914572868,
          1.3819095477386938,
          1.4321608040201008,
          1.4824120603015079,
          1.5326633165829149,
          1.582914572864322,
          1.633165829145729,
          1.683417085427136,
          1.733668341708543,
          1.78391959798995,
          1.834170854271357,
          1.884422110552764,
          1.9346733668341711,
          1.9849246231155782,
          2.035175879396985,
          2.085427135678392,
          2.1356783919597992,
          2.1859296482412063,
          2.2361809045226133,
          2.2864321608040203,
          2.3366834170854274,
          2.3869346733668344,
          2.4371859296482414,
          2.4874371859296485,
          2.5376884422110555,
          2.5879396984924625,
          2.6381909547738696,
          2.6884422110552766,
          2.7386934673366836,
          2.7889447236180906,
          2.8391959798994977,
          2.8894472361809047,
          2.9396984924623117,
          2.9899497487437188,
          3.0402010050251267,
          3.090452261306533,
          3.1407035175879408,
          3.190954773869347,
          3.241206030150755,
          3.291457286432161,
          3.341708542713569,
          3.391959798994975,
          3.442211055276383,
          3.492462311557789,
          3.542713567839197,
          3.592964824120603,
          3.643216080402011,
          3.693467336683417,
          3.743718592964825,
          3.7939698492462313,
          3.844221105527639,
          3.8944723618090453,
          3.9447236180904532,
          3.9949748743718594,
          4.045226130653267,
          4.0954773869346734,
          4.145728643216081,
          4.1959798994974875,
          4.246231155778895,
          4.296482412060302,
          4.3467336683417095,
          4.396984924623116,
          4.4472361809045236,
          4.49748743718593,
          4.547738693467338,
          4.597989949748744,
          4.648241206030152,
          4.698492462311558,
          4.748743718592966,
          4.798994974874372,
          4.84924623115578,
          4.899497487437186,
          4.949748743718594,
          5
         ],
         "y": [
          2.1463837356630605e-32,
          7.133230489121109e-32,
          2.346812773633927e-31,
          7.643353175673106e-31,
          2.4643518195336605e-30,
          7.865653105116217e-30,
          2.485307706855918e-29,
          7.77389806952539e-29,
          2.4071924638365404e-28,
          7.378975801074293e-28,
          2.2392091233729873e-27,
          6.726769116373696e-27,
          2.0004683565553364e-26,
          5.88938774641203e-26,
          1.7164134480175298e-25,
          4.952072183521779e-25,
          1.4143774458566436e-24,
          3.9990513057353024e-24,
          1.1193397517724044e-23,
          3.101559925821268e-23,
          8.507691310755334e-23,
          2.310237178783976e-22,
          6.210330478251203e-22,
          1.6526700319069196e-21,
          4.353824214691362e-21,
          1.135452384523984e-20,
          2.931434945535924e-20,
          7.492122895930944e-20,
          1.895583074931349e-19,
          4.74781786106962e-19,
          1.1772225574596035e-18,
          2.889591149770373e-18,
          7.021461510251246e-18,
          1.6890089012637188e-17,
          4.022070280238714e-17,
          9.48157903547322e-17,
          2.2127124623349315e-16,
          5.111902855003179e-16,
          1.1691049518737339e-15,
          2.6469010475900543e-15,
          5.932465338746881e-15,
          1.3162731151670834e-14,
          2.8911465762800855e-14,
          6.286479553241963e-14,
          1.3531882008602697e-13,
          2.8835148680350603e-13,
          6.082743252881185e-13,
          1.2702525461365896e-12,
          2.625995396118982e-12,
          5.3741668342451615e-12,
          1.0887837397262484e-11,
          2.1836619471228554e-11,
          4.335532874425142e-11,
          8.521437421238857e-11,
          1.6580458358590643e-10,
          3.193695477315732e-10,
          6.089810408640702e-10,
          1.1495486052366015e-09,
          2.1481480193420053e-09,
          3.9738764974129935e-09,
          7.27742646662481e-09,
          1.319333481393963e-08,
          2.3677979472626668e-08,
          4.20676249520529e-08,
          7.398857190757879e-08,
          1.2882335164422093e-07,
          2.2204338595713047e-07,
          3.788736363564433e-07,
          6.39976797833875e-07,
          1.0701566872444483e-06,
          1.7715108153513449e-06,
          2.9030435061172303e-06,
          4.709519272544368e-06,
          7.563327573047441e-06,
          1.2024375780027367e-05,
          1.8924545919900157e-05,
          2.94850380887149e-05,
          4.547693808101849e-05,
          6.943749378655928e-05,
          0.00010495669732889988,
          0.0001570505902692841,
          0.00023263887421947144,
          0.00034114444189664876,
          0.0004952307579072902,
          0.00071168894230022,
          0.00101247923260002,
          0.0014259205488438825,
          0.0019880066332545526,
          0.002743807434250947,
          0.0037488902424956307,
          0.005070667350661259,
          0.0067895472248179775,
          0.008999736706509814,
          0.0118095158260544,
          0.01534078837042205,
          0.01972770490282947,
          0.025114165092530685,
          0.031650037185605745,
          0.039485987363558774,
          0.04876689194371877,
          0.05962390975210613,
          0.07216541641028328,
          0.08646713928646242,
          0.10256197080956149,
          0.12043006537870544,
          0.13998992617365802,
          0.1610912474930448,
          0.18351028206203862,
          0.20694844077003957,
          0.23103469953483863,
          0.25533218622946874,
          0.27934905925223097,
          0.30255348538044763,
          0.32439220167745086,
          0.34431183278711686,
          0.3617818612904054,
          0.3763179439532767,
          0.38750415498851476,
          0.3950127353787847,
          0.39862004115367355,
          0.39821760809314527,
          0.39381756904336157,
          0.3855520463090605,
          0.3736665615802896,
          0.35850792204313137,
          0.34050741661169837,
          0.32016045794352327,
          0.29800400930827603,
          0.2745932260807728,
          0.25047871677185984,
          0.22618569656613793,
          0.20219608558255805,
          0.17893432004468615,
          0.15675732681623833,
          0.13594879051917075,
          0.11671754532688297,
          0.09919967296343765,
          0.08346369997605273,
          0.06951816883131112,
          0.05732080915654202,
          0.0467885513258265,
          0.03780769343881462,
          0.03024364034510724,
          0.02394976435149345,
          0.018775076803323205,
          0.014570534974595997,
          0.011193929593162311,
          0.00851339809848076,
          0.0064096838799737295,
          0.004777311696028684,
          0.0035248759887838705,
          0.0025746452913131025,
          0.001861676707255138,
          0.001332614158263526,
          0.0009443171540943642,
          0.0006624370777956696,
          0.0004600284428262817,
          0.0003162554610820534,
          0.000215230929292481,
          0.00014500555031307871,
          9.671144420245615e-05,
          6.385345620962054e-05,
          4.173536806384566e-05,
          2.7004577332740484e-05,
          1.7297519082622216e-05,
          1.096840682616814e-05,
          6.885200318846564e-06,
          4.2786120291436275e-06,
          2.632100897727713e-06,
          1.6029333198893727e-06,
          9.663660803554825e-07,
          5.767414920972323e-07,
          3.407485476494343e-07,
          1.9929670937730613e-07,
          1.153930202312381e-07,
          6.614122751648698e-08,
          3.7529973591539826e-08,
          2.108130855032396e-08,
          1.1722767954568624e-08,
          6.453214040206488e-09,
          3.5166995788146016e-09,
          1.897176631710412e-09,
          1.0131962218816929e-09,
          5.35664239925679e-10,
          2.803528950926853e-10,
          1.4525488061940943e-10,
          7.450230683244045e-11,
          3.7828751170808954e-11,
          1.9014617183781176e-11,
          9.46164100876659e-12,
          4.660780430507926e-12,
          2.2728151691271506e-12,
          1.0971926574413598e-12,
          5.24342383281561e-13,
          2.480620524416489e-13,
          1.1617669018352842e-13,
          5.3863052773750524e-14,
          2.4721580154351614e-14,
          1.1232457571901753e-14,
          5.052271083536893e-15
         ]
        },
        {
         "line": {
          "color": "rgb(0, 0, 0)",
          "dash": "dot"
         },
         "mode": "lines",
         "name": "boundary 1",
         "text": [
          "0.53"
         ],
         "textposition": "bottom center",
         "type": "scatter",
         "uid": "cd0beeed-8f3e-4ef8-b630-d1114d342b0a",
         "x": [
          0.53,
          0.53
         ],
         "y": [
          0,
          0.45
         ]
        },
        {
         "line": {
          "color": "rgb(0, 0, 0)",
          "dash": "dot"
         },
         "mode": "lines",
         "name": "boundary 2",
         "text": [
          "1.73"
         ],
         "textposition": "bottom center",
         "type": "scatter",
         "uid": "7f40be15-4e90-429e-9132-ab7f1d1eb481",
         "x": [
          1.73,
          1.73
         ],
         "y": [
          0,
          0.45
         ]
        }
       ],
       "layout": {
        "showlegend": true,
        "title": "Likelihood times the prior, for both classes"
       }
      },
      "text/html": [
       "<div id=\"2082498a-bfdc-4923-8971-1a043963628c\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2082498a-bfdc-4923-8971-1a043963628c\", [{\"name\": \"class 0\", \"x\": [-5.0, -4.949748743718593, -4.899497487437186, -4.849246231155779, -4.798994974874372, -4.748743718592965, -4.698492462311558, -4.648241206030151, -4.597989949748744, -4.547738693467337, -4.49748743718593, -4.447236180904523, -4.396984924623116, -4.346733668341709, -4.296482412060302, -4.2462311557788945, -4.1959798994974875, -4.1457286432160805, -4.0954773869346734, -4.045226130653266, -3.9949748743718594, -3.9447236180904524, -3.8944723618090453, -3.8442211055276383, -3.7939698492462313, -3.7437185929648242, -3.693467336683417, -3.64321608040201, -3.592964824120603, -3.542713567839196, -3.492462311557789, -3.442211055276382, -3.391959798994975, -3.341708542713568, -3.291457286432161, -3.241206030150754, -3.190954773869347, -3.14070351758794, -3.090452261306533, -3.040201005025126, -2.9899497487437183, -2.9396984924623113, -2.8894472361809043, -2.8391959798994972, -2.78894472361809, -2.738693467336683, -2.688442211055276, -2.638190954773869, -2.587939698492462, -2.537688442211055, -2.487437185929648, -2.437185929648241, -2.386934673366834, -2.336683417085427, -2.28643216080402, -2.236180904522613, -2.185929648241206, -2.135678391959799, -2.0854271356783918, -2.0351758793969847, -1.9849246231155777, -1.9346733668341707, -1.8844221105527637, -1.8341708542713566, -1.7839195979899496, -1.7336683417085426, -1.6834170854271355, -1.6331658291457285, -1.5829145728643215, -1.5326633165829144, -1.4824120603015074, -1.4321608040201004, -1.3819095477386933, -1.3316582914572863, -1.2814070351758793, -1.2311557788944723, -1.1809045226130652, -1.1306532663316582, -1.0804020100502512, -1.0301507537688441, -0.9798994974874367, -0.9296482412060296, -0.8793969849246226, -0.8291457286432156, -0.7788944723618085, -0.7286432160804015, -0.6783919597989945, -0.6281407035175874, -0.5778894472361804, -0.5276381909547734, -0.47738693467336635, -0.4271356783919593, -0.3768844221105523, -0.32663316582914526, -0.2763819095477382, -0.2261306532663312, -0.17587939698492416, -0.12562814070351713, -0.0753768844221101, -0.02512562814070307, 0.02512562814070396, 0.07537688442211099, 0.12562814070351802, 0.17587939698492505, 0.22613065326633208, 0.2763819095477391, 0.32663316582914614, 0.3768844221105532, 0.4271356783919602, 0.47738693467336724, 0.5276381909547743, 0.5778894472361813, 0.6281407035175883, 0.6783919597989954, 0.7286432160804024, 0.7788944723618094, 0.8291457286432165, 0.8793969849246235, 0.9296482412060305, 0.9798994974874375, 1.0301507537688446, 1.0804020100502516, 1.1306532663316586, 1.1809045226130657, 1.2311557788944727, 1.2814070351758797, 1.3316582914572868, 1.3819095477386938, 1.4321608040201008, 1.4824120603015079, 1.5326633165829149, 1.582914572864322, 1.633165829145729, 1.683417085427136, 1.733668341708543, 1.78391959798995, 1.834170854271357, 1.884422110552764, 1.9346733668341711, 1.9849246231155782, 2.035175879396985, 2.085427135678392, 2.1356783919597992, 2.1859296482412063, 2.2361809045226133, 2.2864321608040203, 2.3366834170854274, 2.3869346733668344, 2.4371859296482414, 2.4874371859296485, 2.5376884422110555, 2.5879396984924625, 2.6381909547738696, 2.6884422110552766, 2.7386934673366836, 2.7889447236180906, 2.8391959798994977, 2.8894472361809047, 2.9396984924623117, 2.9899497487437188, 3.0402010050251267, 3.090452261306533, 3.1407035175879408, 3.190954773869347, 3.241206030150755, 3.291457286432161, 3.341708542713569, 3.391959798994975, 3.442211055276383, 3.492462311557789, 3.542713567839197, 3.592964824120603, 3.643216080402011, 3.693467336683417, 3.743718592964825, 3.7939698492462313, 3.844221105527639, 3.8944723618090453, 3.9447236180904532, 3.9949748743718594, 4.045226130653267, 4.0954773869346734, 4.145728643216081, 4.1959798994974875, 4.246231155778895, 4.296482412060302, 4.3467336683417095, 4.396984924623116, 4.4472361809045236, 4.49748743718593, 4.547738693467338, 4.597989949748744, 4.648241206030152, 4.698492462311558, 4.748743718592966, 4.798994974874372, 4.84924623115578, 4.899497487437186, 4.949748743718594, 5.0], \"y\": [0.0010281859975274045, 0.0011490142345814737, 0.0012826014351765447, 0.0014301138833504145, 0.0015928031745197717, 0.001772010092479435, 0.0019691684016190742, 0.0021858085177893375, 0.0024235610181197915, 0.0026841599469854325, 0.002969445872272179, 0.0032813686431437078, 0.003621989797704343, 0.003993484566330498, 0.004398143414053857, 0.0048383730632731185, 0.005316696936299597, 0.005835754955858536, 0.006398302640726588, 0.00700720943324149, 0.00766545619552614, 0.008376131811979125, 0.009142428836948503, 0.009967638128573117, 0.010855142412591027, 0.011808408723517277, 0.012830979675018051, 0.01392646351658327, 0.015098522939745217, 0.016350862604119498, 0.017687215361459157, 0.01911132716470631, 0.020626940658680502, 0.02223777745952852, 0.023947519141336953, 0.025759786960320295, 0.0276781203596774, 0.029705954311478065, 0.03184659556570474, 0.0341031978907266, 0.036478736403905504, 0.03897598110559366, 0.041597469744342266, 0.044345480155541996, 0.04722200222980392, 0.050228709680990705, 0.05336693179675048, 0.056637625366509174, 0.06004134699296218, 0.06357822600299094, 0.06724793818243621, 0.07104968056611516, 0.07498214751970457, 0.07904350835347554, 0.08323138670920636, 0.08754284196079627, 0.09197435286603677, 0.09652180370158164, 0.1011804731053182, 0.10594502584003766, 0.11080950767951012, 0.11576734360280043, 0.12081133946494639, 0.12593368729203372, 0.1311259743263341, 0.13637919592265363, 0.14168377237052615, 0.14702956968856742, 0.152405924407396, 0.15780167232626957, 0.16320518119625044, 0.168604387249589, 0.17398683546141247, 0.1793397233960552, 0.18464994845680777, 0.18990415832484223, 0.19508880434095327, 0.20019019755288744, 0.20519456712177644, 0.2100881207538881, 0.21485710679889372, 0.21948787763343955, 0.22396695392930252, 0.22828108938906622, 0.2324173355193272, 0.23636310600212554, 0.24010624021977184, 0.24363506548663535, 0.24693845754386423, 0.25000589887946556, 0.2528275344466883, 0.25539422436817777, 0.2576975932318133, 0.2597300756063714, 0.2614849574309861, 0.26295641296159, 0.2641395369898463, 0.2650303720852233, 0.2656259306484852, 0.26592421160461105, 0.26592421160461105, 0.2656259306484852, 0.2650303720852233, 0.2641395369898463, 0.26295641296159, 0.26148495743098604, 0.25973007560637135, 0.2576975932318133, 0.25539422436817777, 0.25282753444668826, 0.2500058988794655, 0.24693845754386418, 0.2436350654866353, 0.24010624021977178, 0.23636310600212548, 0.2324173355193271, 0.22828108938906613, 0.2239669539293024, 0.21948787763343947, 0.21485710679889364, 0.21008812075388808, 0.20519456712177636, 0.20019019755288736, 0.19508880434095321, 0.18990415832484217, 0.1846499484568077, 0.17933972339605517, 0.17398683546141241, 0.16860438724958896, 0.16320518119625038, 0.15780167232626952, 0.15240592440739598, 0.14702956968856737, 0.1416837723705261, 0.1363791959226536, 0.13112597432633408, 0.12593368729203366, 0.12081133946494632, 0.11576734360280039, 0.11080950767951007, 0.1059450258400376, 0.10118047310531818, 0.09652180370158159, 0.09197435286603671, 0.08754284196079623, 0.08323138670920635, 0.07904350835347551, 0.07498214751970454, 0.07104968056611513, 0.06724793818243618, 0.0635782260029909, 0.06004134699296216, 0.05663762536650913, 0.05336693179675045, 0.05022870968099068, 0.047222002229803876, 0.044345480155541975, 0.04159746974434223, 0.038975981105593624, 0.036478736403905476, 0.034103197890726564, 0.03184659556570474, 0.029705954311478027, 0.0276781203596774, 0.025759786960320264, 0.023947519141336953, 0.022237777459528478, 0.020626940658680502, 0.019111327164706288, 0.017687215361459157, 0.016350862604119484, 0.015098522939745217, 0.013926463516583252, 0.012830979675018051, 0.011808408723517261, 0.010855142412591027, 0.009967638128573101, 0.009142428836948503, 0.008376131811979111, 0.00766545619552614, 0.007007209433241478, 0.006398302640726588, 0.005835754955858525, 0.005316696936299597, 0.0048383730632731055, 0.004398143414053857, 0.0039934845663304915, 0.003621989797704343, 0.0032813686431437043, 0.002969445872272179, 0.0026841599469854278, 0.0024235610181197915, 0.002185808517789334, 0.0019691684016190742, 0.0017720100924794302, 0.0015928031745197717, 0.0014301138833504106, 0.0012826014351765447, 0.0011490142345814706, 0.0010281859975274045], \"type\": \"scatter\", \"uid\": \"99b03f2f-cd79-4f52-b1e2-a53325315262\"}, {\"name\": \"class 1\", \"x\": [-5.0, -4.949748743718593, -4.899497487437186, -4.849246231155779, -4.798994974874372, -4.748743718592965, -4.698492462311558, -4.648241206030151, -4.597989949748744, -4.547738693467337, -4.49748743718593, -4.447236180904523, -4.396984924623116, -4.346733668341709, -4.296482412060302, -4.2462311557788945, -4.1959798994974875, -4.1457286432160805, -4.0954773869346734, -4.045226130653266, -3.9949748743718594, -3.9447236180904524, -3.8944723618090453, -3.8442211055276383, -3.7939698492462313, -3.7437185929648242, -3.693467336683417, -3.64321608040201, -3.592964824120603, -3.542713567839196, -3.492462311557789, -3.442211055276382, -3.391959798994975, -3.341708542713568, -3.291457286432161, -3.241206030150754, -3.190954773869347, -3.14070351758794, -3.090452261306533, -3.040201005025126, -2.9899497487437183, -2.9396984924623113, -2.8894472361809043, -2.8391959798994972, -2.78894472361809, -2.738693467336683, -2.688442211055276, -2.638190954773869, -2.587939698492462, -2.537688442211055, -2.487437185929648, -2.437185929648241, -2.386934673366834, -2.336683417085427, -2.28643216080402, -2.236180904522613, -2.185929648241206, -2.135678391959799, -2.0854271356783918, -2.0351758793969847, -1.9849246231155777, -1.9346733668341707, -1.8844221105527637, -1.8341708542713566, -1.7839195979899496, -1.7336683417085426, -1.6834170854271355, -1.6331658291457285, -1.5829145728643215, -1.5326633165829144, -1.4824120603015074, -1.4321608040201004, -1.3819095477386933, -1.3316582914572863, -1.2814070351758793, -1.2311557788944723, -1.1809045226130652, -1.1306532663316582, -1.0804020100502512, -1.0301507537688441, -0.9798994974874367, -0.9296482412060296, -0.8793969849246226, -0.8291457286432156, -0.7788944723618085, -0.7286432160804015, -0.6783919597989945, -0.6281407035175874, -0.5778894472361804, -0.5276381909547734, -0.47738693467336635, -0.4271356783919593, -0.3768844221105523, -0.32663316582914526, -0.2763819095477382, -0.2261306532663312, -0.17587939698492416, -0.12562814070351713, -0.0753768844221101, -0.02512562814070307, 0.02512562814070396, 0.07537688442211099, 0.12562814070351802, 0.17587939698492505, 0.22613065326633208, 0.2763819095477391, 0.32663316582914614, 0.3768844221105532, 0.4271356783919602, 0.47738693467336724, 0.5276381909547743, 0.5778894472361813, 0.6281407035175883, 0.6783919597989954, 0.7286432160804024, 0.7788944723618094, 0.8291457286432165, 0.8793969849246235, 0.9296482412060305, 0.9798994974874375, 1.0301507537688446, 1.0804020100502516, 1.1306532663316586, 1.1809045226130657, 1.2311557788944727, 1.2814070351758797, 1.3316582914572868, 1.3819095477386938, 1.4321608040201008, 1.4824120603015079, 1.5326633165829149, 1.582914572864322, 1.633165829145729, 1.683417085427136, 1.733668341708543, 1.78391959798995, 1.834170854271357, 1.884422110552764, 1.9346733668341711, 1.9849246231155782, 2.035175879396985, 2.085427135678392, 2.1356783919597992, 2.1859296482412063, 2.2361809045226133, 2.2864321608040203, 2.3366834170854274, 2.3869346733668344, 2.4371859296482414, 2.4874371859296485, 2.5376884422110555, 2.5879396984924625, 2.6381909547738696, 2.6884422110552766, 2.7386934673366836, 2.7889447236180906, 2.8391959798994977, 2.8894472361809047, 2.9396984924623117, 2.9899497487437188, 3.0402010050251267, 3.090452261306533, 3.1407035175879408, 3.190954773869347, 3.241206030150755, 3.291457286432161, 3.341708542713569, 3.391959798994975, 3.442211055276383, 3.492462311557789, 3.542713567839197, 3.592964824120603, 3.643216080402011, 3.693467336683417, 3.743718592964825, 3.7939698492462313, 3.844221105527639, 3.8944723618090453, 3.9447236180904532, 3.9949748743718594, 4.045226130653267, 4.0954773869346734, 4.145728643216081, 4.1959798994974875, 4.246231155778895, 4.296482412060302, 4.3467336683417095, 4.396984924623116, 4.4472361809045236, 4.49748743718593, 4.547738693467338, 4.597989949748744, 4.648241206030152, 4.698492462311558, 4.748743718592966, 4.798994974874372, 4.84924623115578, 4.899497487437186, 4.949748743718594, 5.0], \"y\": [2.1463837356630605e-32, 7.133230489121109e-32, 2.346812773633927e-31, 7.643353175673106e-31, 2.4643518195336605e-30, 7.865653105116217e-30, 2.485307706855918e-29, 7.77389806952539e-29, 2.4071924638365404e-28, 7.378975801074293e-28, 2.2392091233729873e-27, 6.726769116373696e-27, 2.0004683565553364e-26, 5.88938774641203e-26, 1.7164134480175298e-25, 4.952072183521779e-25, 1.4143774458566436e-24, 3.9990513057353024e-24, 1.1193397517724044e-23, 3.101559925821268e-23, 8.507691310755334e-23, 2.310237178783976e-22, 6.210330478251203e-22, 1.6526700319069196e-21, 4.353824214691362e-21, 1.135452384523984e-20, 2.931434945535924e-20, 7.492122895930944e-20, 1.895583074931349e-19, 4.74781786106962e-19, 1.1772225574596035e-18, 2.889591149770373e-18, 7.021461510251246e-18, 1.6890089012637188e-17, 4.022070280238714e-17, 9.48157903547322e-17, 2.2127124623349315e-16, 5.111902855003179e-16, 1.1691049518737339e-15, 2.6469010475900543e-15, 5.932465338746881e-15, 1.3162731151670834e-14, 2.8911465762800855e-14, 6.286479553241963e-14, 1.3531882008602697e-13, 2.8835148680350603e-13, 6.082743252881185e-13, 1.2702525461365896e-12, 2.625995396118982e-12, 5.3741668342451615e-12, 1.0887837397262484e-11, 2.1836619471228554e-11, 4.335532874425142e-11, 8.521437421238857e-11, 1.6580458358590643e-10, 3.193695477315732e-10, 6.089810408640702e-10, 1.1495486052366015e-09, 2.1481480193420053e-09, 3.9738764974129935e-09, 7.27742646662481e-09, 1.319333481393963e-08, 2.3677979472626668e-08, 4.20676249520529e-08, 7.398857190757879e-08, 1.2882335164422093e-07, 2.2204338595713047e-07, 3.788736363564433e-07, 6.39976797833875e-07, 1.0701566872444483e-06, 1.7715108153513449e-06, 2.9030435061172303e-06, 4.709519272544368e-06, 7.563327573047441e-06, 1.2024375780027367e-05, 1.8924545919900157e-05, 2.94850380887149e-05, 4.547693808101849e-05, 6.943749378655928e-05, 0.00010495669732889988, 0.0001570505902692841, 0.00023263887421947144, 0.00034114444189664876, 0.0004952307579072902, 0.00071168894230022, 0.00101247923260002, 0.0014259205488438825, 0.0019880066332545526, 0.002743807434250947, 0.0037488902424956307, 0.005070667350661259, 0.0067895472248179775, 0.008999736706509814, 0.0118095158260544, 0.01534078837042205, 0.01972770490282947, 0.025114165092530685, 0.031650037185605745, 0.039485987363558774, 0.04876689194371877, 0.05962390975210613, 0.07216541641028328, 0.08646713928646242, 0.10256197080956149, 0.12043006537870544, 0.13998992617365802, 0.1610912474930448, 0.18351028206203862, 0.20694844077003957, 0.23103469953483863, 0.25533218622946874, 0.27934905925223097, 0.30255348538044763, 0.32439220167745086, 0.34431183278711686, 0.3617818612904054, 0.3763179439532767, 0.38750415498851476, 0.3950127353787847, 0.39862004115367355, 0.39821760809314527, 0.39381756904336157, 0.3855520463090605, 0.3736665615802896, 0.35850792204313137, 0.34050741661169837, 0.32016045794352327, 0.29800400930827603, 0.2745932260807728, 0.25047871677185984, 0.22618569656613793, 0.20219608558255805, 0.17893432004468615, 0.15675732681623833, 0.13594879051917075, 0.11671754532688297, 0.09919967296343765, 0.08346369997605273, 0.06951816883131112, 0.05732080915654202, 0.0467885513258265, 0.03780769343881462, 0.03024364034510724, 0.02394976435149345, 0.018775076803323205, 0.014570534974595997, 0.011193929593162311, 0.00851339809848076, 0.0064096838799737295, 0.004777311696028684, 0.0035248759887838705, 0.0025746452913131025, 0.001861676707255138, 0.001332614158263526, 0.0009443171540943642, 0.0006624370777956696, 0.0004600284428262817, 0.0003162554610820534, 0.000215230929292481, 0.00014500555031307871, 9.671144420245615e-05, 6.385345620962054e-05, 4.173536806384566e-05, 2.7004577332740484e-05, 1.7297519082622216e-05, 1.096840682616814e-05, 6.885200318846564e-06, 4.2786120291436275e-06, 2.632100897727713e-06, 1.6029333198893727e-06, 9.663660803554825e-07, 5.767414920972323e-07, 3.407485476494343e-07, 1.9929670937730613e-07, 1.153930202312381e-07, 6.614122751648698e-08, 3.7529973591539826e-08, 2.108130855032396e-08, 1.1722767954568624e-08, 6.453214040206488e-09, 3.5166995788146016e-09, 1.897176631710412e-09, 1.0131962218816929e-09, 5.35664239925679e-10, 2.803528950926853e-10, 1.4525488061940943e-10, 7.450230683244045e-11, 3.7828751170808954e-11, 1.9014617183781176e-11, 9.46164100876659e-12, 4.660780430507926e-12, 2.2728151691271506e-12, 1.0971926574413598e-12, 5.24342383281561e-13, 2.480620524416489e-13, 1.1617669018352842e-13, 5.3863052773750524e-14, 2.4721580154351614e-14, 1.1232457571901753e-14, 5.052271083536893e-15], \"type\": \"scatter\", \"uid\": \"1318b6bc-6260-4bd6-bfbc-4a01a8cbdcf1\"}, {\"line\": {\"color\": \"rgb(0, 0, 0)\", \"dash\": \"dot\"}, \"mode\": \"lines\", \"name\": \"boundary 1\", \"text\": [\"0.53\"], \"textposition\": \"bottom center\", \"x\": [0.53, 0.53], \"y\": [0, 0.45], \"type\": \"scatter\", \"uid\": \"cd0beeed-8f3e-4ef8-b630-d1114d342b0a\"}, {\"line\": {\"color\": \"rgb(0, 0, 0)\", \"dash\": \"dot\"}, \"mode\": \"lines\", \"name\": \"boundary 2\", \"text\": [\"1.73\"], \"textposition\": \"bottom center\", \"x\": [1.73, 1.73], \"y\": [0, 0.45], \"type\": \"scatter\", \"uid\": \"7f40be15-4e90-429e-9132-ab7f1d1eb481\"}], {\"showlegend\": true, \"title\": \"Likelihood times the prior, for both classes\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"2082498a-bfdc-4923-8971-1a043963628c\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"2082498a-bfdc-4923-8971-1a043963628c\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2082498a-bfdc-4923-8971-1a043963628c\", [{\"name\": \"class 0\", \"x\": [-5.0, -4.949748743718593, -4.899497487437186, -4.849246231155779, -4.798994974874372, -4.748743718592965, -4.698492462311558, -4.648241206030151, -4.597989949748744, -4.547738693467337, -4.49748743718593, -4.447236180904523, -4.396984924623116, -4.346733668341709, -4.296482412060302, -4.2462311557788945, -4.1959798994974875, -4.1457286432160805, -4.0954773869346734, -4.045226130653266, -3.9949748743718594, -3.9447236180904524, -3.8944723618090453, -3.8442211055276383, -3.7939698492462313, -3.7437185929648242, -3.693467336683417, -3.64321608040201, -3.592964824120603, -3.542713567839196, -3.492462311557789, -3.442211055276382, -3.391959798994975, -3.341708542713568, -3.291457286432161, -3.241206030150754, -3.190954773869347, -3.14070351758794, -3.090452261306533, -3.040201005025126, -2.9899497487437183, -2.9396984924623113, -2.8894472361809043, -2.8391959798994972, -2.78894472361809, -2.738693467336683, -2.688442211055276, -2.638190954773869, -2.587939698492462, -2.537688442211055, -2.487437185929648, -2.437185929648241, -2.386934673366834, -2.336683417085427, -2.28643216080402, -2.236180904522613, -2.185929648241206, -2.135678391959799, -2.0854271356783918, -2.0351758793969847, -1.9849246231155777, -1.9346733668341707, -1.8844221105527637, -1.8341708542713566, -1.7839195979899496, -1.7336683417085426, -1.6834170854271355, -1.6331658291457285, -1.5829145728643215, -1.5326633165829144, -1.4824120603015074, -1.4321608040201004, -1.3819095477386933, -1.3316582914572863, -1.2814070351758793, -1.2311557788944723, -1.1809045226130652, -1.1306532663316582, -1.0804020100502512, -1.0301507537688441, -0.9798994974874367, -0.9296482412060296, -0.8793969849246226, -0.8291457286432156, -0.7788944723618085, -0.7286432160804015, -0.6783919597989945, -0.6281407035175874, -0.5778894472361804, -0.5276381909547734, -0.47738693467336635, -0.4271356783919593, -0.3768844221105523, -0.32663316582914526, -0.2763819095477382, -0.2261306532663312, -0.17587939698492416, -0.12562814070351713, -0.0753768844221101, -0.02512562814070307, 0.02512562814070396, 0.07537688442211099, 0.12562814070351802, 0.17587939698492505, 0.22613065326633208, 0.2763819095477391, 0.32663316582914614, 0.3768844221105532, 0.4271356783919602, 0.47738693467336724, 0.5276381909547743, 0.5778894472361813, 0.6281407035175883, 0.6783919597989954, 0.7286432160804024, 0.7788944723618094, 0.8291457286432165, 0.8793969849246235, 0.9296482412060305, 0.9798994974874375, 1.0301507537688446, 1.0804020100502516, 1.1306532663316586, 1.1809045226130657, 1.2311557788944727, 1.2814070351758797, 1.3316582914572868, 1.3819095477386938, 1.4321608040201008, 1.4824120603015079, 1.5326633165829149, 1.582914572864322, 1.633165829145729, 1.683417085427136, 1.733668341708543, 1.78391959798995, 1.834170854271357, 1.884422110552764, 1.9346733668341711, 1.9849246231155782, 2.035175879396985, 2.085427135678392, 2.1356783919597992, 2.1859296482412063, 2.2361809045226133, 2.2864321608040203, 2.3366834170854274, 2.3869346733668344, 2.4371859296482414, 2.4874371859296485, 2.5376884422110555, 2.5879396984924625, 2.6381909547738696, 2.6884422110552766, 2.7386934673366836, 2.7889447236180906, 2.8391959798994977, 2.8894472361809047, 2.9396984924623117, 2.9899497487437188, 3.0402010050251267, 3.090452261306533, 3.1407035175879408, 3.190954773869347, 3.241206030150755, 3.291457286432161, 3.341708542713569, 3.391959798994975, 3.442211055276383, 3.492462311557789, 3.542713567839197, 3.592964824120603, 3.643216080402011, 3.693467336683417, 3.743718592964825, 3.7939698492462313, 3.844221105527639, 3.8944723618090453, 3.9447236180904532, 3.9949748743718594, 4.045226130653267, 4.0954773869346734, 4.145728643216081, 4.1959798994974875, 4.246231155778895, 4.296482412060302, 4.3467336683417095, 4.396984924623116, 4.4472361809045236, 4.49748743718593, 4.547738693467338, 4.597989949748744, 4.648241206030152, 4.698492462311558, 4.748743718592966, 4.798994974874372, 4.84924623115578, 4.899497487437186, 4.949748743718594, 5.0], \"y\": [0.0010281859975274045, 0.0011490142345814737, 0.0012826014351765447, 0.0014301138833504145, 0.0015928031745197717, 0.001772010092479435, 0.0019691684016190742, 0.0021858085177893375, 0.0024235610181197915, 0.0026841599469854325, 0.002969445872272179, 0.0032813686431437078, 0.003621989797704343, 0.003993484566330498, 0.004398143414053857, 0.0048383730632731185, 0.005316696936299597, 0.005835754955858536, 0.006398302640726588, 0.00700720943324149, 0.00766545619552614, 0.008376131811979125, 0.009142428836948503, 0.009967638128573117, 0.010855142412591027, 0.011808408723517277, 0.012830979675018051, 0.01392646351658327, 0.015098522939745217, 0.016350862604119498, 0.017687215361459157, 0.01911132716470631, 0.020626940658680502, 0.02223777745952852, 0.023947519141336953, 0.025759786960320295, 0.0276781203596774, 0.029705954311478065, 0.03184659556570474, 0.0341031978907266, 0.036478736403905504, 0.03897598110559366, 0.041597469744342266, 0.044345480155541996, 0.04722200222980392, 0.050228709680990705, 0.05336693179675048, 0.056637625366509174, 0.06004134699296218, 0.06357822600299094, 0.06724793818243621, 0.07104968056611516, 0.07498214751970457, 0.07904350835347554, 0.08323138670920636, 0.08754284196079627, 0.09197435286603677, 0.09652180370158164, 0.1011804731053182, 0.10594502584003766, 0.11080950767951012, 0.11576734360280043, 0.12081133946494639, 0.12593368729203372, 0.1311259743263341, 0.13637919592265363, 0.14168377237052615, 0.14702956968856742, 0.152405924407396, 0.15780167232626957, 0.16320518119625044, 0.168604387249589, 0.17398683546141247, 0.1793397233960552, 0.18464994845680777, 0.18990415832484223, 0.19508880434095327, 0.20019019755288744, 0.20519456712177644, 0.2100881207538881, 0.21485710679889372, 0.21948787763343955, 0.22396695392930252, 0.22828108938906622, 0.2324173355193272, 0.23636310600212554, 0.24010624021977184, 0.24363506548663535, 0.24693845754386423, 0.25000589887946556, 0.2528275344466883, 0.25539422436817777, 0.2576975932318133, 0.2597300756063714, 0.2614849574309861, 0.26295641296159, 0.2641395369898463, 0.2650303720852233, 0.2656259306484852, 0.26592421160461105, 0.26592421160461105, 0.2656259306484852, 0.2650303720852233, 0.2641395369898463, 0.26295641296159, 0.26148495743098604, 0.25973007560637135, 0.2576975932318133, 0.25539422436817777, 0.25282753444668826, 0.2500058988794655, 0.24693845754386418, 0.2436350654866353, 0.24010624021977178, 0.23636310600212548, 0.2324173355193271, 0.22828108938906613, 0.2239669539293024, 0.21948787763343947, 0.21485710679889364, 0.21008812075388808, 0.20519456712177636, 0.20019019755288736, 0.19508880434095321, 0.18990415832484217, 0.1846499484568077, 0.17933972339605517, 0.17398683546141241, 0.16860438724958896, 0.16320518119625038, 0.15780167232626952, 0.15240592440739598, 0.14702956968856737, 0.1416837723705261, 0.1363791959226536, 0.13112597432633408, 0.12593368729203366, 0.12081133946494632, 0.11576734360280039, 0.11080950767951007, 0.1059450258400376, 0.10118047310531818, 0.09652180370158159, 0.09197435286603671, 0.08754284196079623, 0.08323138670920635, 0.07904350835347551, 0.07498214751970454, 0.07104968056611513, 0.06724793818243618, 0.0635782260029909, 0.06004134699296216, 0.05663762536650913, 0.05336693179675045, 0.05022870968099068, 0.047222002229803876, 0.044345480155541975, 0.04159746974434223, 0.038975981105593624, 0.036478736403905476, 0.034103197890726564, 0.03184659556570474, 0.029705954311478027, 0.0276781203596774, 0.025759786960320264, 0.023947519141336953, 0.022237777459528478, 0.020626940658680502, 0.019111327164706288, 0.017687215361459157, 0.016350862604119484, 0.015098522939745217, 0.013926463516583252, 0.012830979675018051, 0.011808408723517261, 0.010855142412591027, 0.009967638128573101, 0.009142428836948503, 0.008376131811979111, 0.00766545619552614, 0.007007209433241478, 0.006398302640726588, 0.005835754955858525, 0.005316696936299597, 0.0048383730632731055, 0.004398143414053857, 0.0039934845663304915, 0.003621989797704343, 0.0032813686431437043, 0.002969445872272179, 0.0026841599469854278, 0.0024235610181197915, 0.002185808517789334, 0.0019691684016190742, 0.0017720100924794302, 0.0015928031745197717, 0.0014301138833504106, 0.0012826014351765447, 0.0011490142345814706, 0.0010281859975274045], \"type\": \"scatter\", \"uid\": \"99b03f2f-cd79-4f52-b1e2-a53325315262\"}, {\"name\": \"class 1\", \"x\": [-5.0, -4.949748743718593, -4.899497487437186, -4.849246231155779, -4.798994974874372, -4.748743718592965, -4.698492462311558, -4.648241206030151, -4.597989949748744, -4.547738693467337, -4.49748743718593, -4.447236180904523, -4.396984924623116, -4.346733668341709, -4.296482412060302, -4.2462311557788945, -4.1959798994974875, -4.1457286432160805, -4.0954773869346734, -4.045226130653266, -3.9949748743718594, -3.9447236180904524, -3.8944723618090453, -3.8442211055276383, -3.7939698492462313, -3.7437185929648242, -3.693467336683417, -3.64321608040201, -3.592964824120603, -3.542713567839196, -3.492462311557789, -3.442211055276382, -3.391959798994975, -3.341708542713568, -3.291457286432161, -3.241206030150754, -3.190954773869347, -3.14070351758794, -3.090452261306533, -3.040201005025126, -2.9899497487437183, -2.9396984924623113, -2.8894472361809043, -2.8391959798994972, -2.78894472361809, -2.738693467336683, -2.688442211055276, -2.638190954773869, -2.587939698492462, -2.537688442211055, -2.487437185929648, -2.437185929648241, -2.386934673366834, -2.336683417085427, -2.28643216080402, -2.236180904522613, -2.185929648241206, -2.135678391959799, -2.0854271356783918, -2.0351758793969847, -1.9849246231155777, -1.9346733668341707, -1.8844221105527637, -1.8341708542713566, -1.7839195979899496, -1.7336683417085426, -1.6834170854271355, -1.6331658291457285, -1.5829145728643215, -1.5326633165829144, -1.4824120603015074, -1.4321608040201004, -1.3819095477386933, -1.3316582914572863, -1.2814070351758793, -1.2311557788944723, -1.1809045226130652, -1.1306532663316582, -1.0804020100502512, -1.0301507537688441, -0.9798994974874367, -0.9296482412060296, -0.8793969849246226, -0.8291457286432156, -0.7788944723618085, -0.7286432160804015, -0.6783919597989945, -0.6281407035175874, -0.5778894472361804, -0.5276381909547734, -0.47738693467336635, -0.4271356783919593, -0.3768844221105523, -0.32663316582914526, -0.2763819095477382, -0.2261306532663312, -0.17587939698492416, -0.12562814070351713, -0.0753768844221101, -0.02512562814070307, 0.02512562814070396, 0.07537688442211099, 0.12562814070351802, 0.17587939698492505, 0.22613065326633208, 0.2763819095477391, 0.32663316582914614, 0.3768844221105532, 0.4271356783919602, 0.47738693467336724, 0.5276381909547743, 0.5778894472361813, 0.6281407035175883, 0.6783919597989954, 0.7286432160804024, 0.7788944723618094, 0.8291457286432165, 0.8793969849246235, 0.9296482412060305, 0.9798994974874375, 1.0301507537688446, 1.0804020100502516, 1.1306532663316586, 1.1809045226130657, 1.2311557788944727, 1.2814070351758797, 1.3316582914572868, 1.3819095477386938, 1.4321608040201008, 1.4824120603015079, 1.5326633165829149, 1.582914572864322, 1.633165829145729, 1.683417085427136, 1.733668341708543, 1.78391959798995, 1.834170854271357, 1.884422110552764, 1.9346733668341711, 1.9849246231155782, 2.035175879396985, 2.085427135678392, 2.1356783919597992, 2.1859296482412063, 2.2361809045226133, 2.2864321608040203, 2.3366834170854274, 2.3869346733668344, 2.4371859296482414, 2.4874371859296485, 2.5376884422110555, 2.5879396984924625, 2.6381909547738696, 2.6884422110552766, 2.7386934673366836, 2.7889447236180906, 2.8391959798994977, 2.8894472361809047, 2.9396984924623117, 2.9899497487437188, 3.0402010050251267, 3.090452261306533, 3.1407035175879408, 3.190954773869347, 3.241206030150755, 3.291457286432161, 3.341708542713569, 3.391959798994975, 3.442211055276383, 3.492462311557789, 3.542713567839197, 3.592964824120603, 3.643216080402011, 3.693467336683417, 3.743718592964825, 3.7939698492462313, 3.844221105527639, 3.8944723618090453, 3.9447236180904532, 3.9949748743718594, 4.045226130653267, 4.0954773869346734, 4.145728643216081, 4.1959798994974875, 4.246231155778895, 4.296482412060302, 4.3467336683417095, 4.396984924623116, 4.4472361809045236, 4.49748743718593, 4.547738693467338, 4.597989949748744, 4.648241206030152, 4.698492462311558, 4.748743718592966, 4.798994974874372, 4.84924623115578, 4.899497487437186, 4.949748743718594, 5.0], \"y\": [2.1463837356630605e-32, 7.133230489121109e-32, 2.346812773633927e-31, 7.643353175673106e-31, 2.4643518195336605e-30, 7.865653105116217e-30, 2.485307706855918e-29, 7.77389806952539e-29, 2.4071924638365404e-28, 7.378975801074293e-28, 2.2392091233729873e-27, 6.726769116373696e-27, 2.0004683565553364e-26, 5.88938774641203e-26, 1.7164134480175298e-25, 4.952072183521779e-25, 1.4143774458566436e-24, 3.9990513057353024e-24, 1.1193397517724044e-23, 3.101559925821268e-23, 8.507691310755334e-23, 2.310237178783976e-22, 6.210330478251203e-22, 1.6526700319069196e-21, 4.353824214691362e-21, 1.135452384523984e-20, 2.931434945535924e-20, 7.492122895930944e-20, 1.895583074931349e-19, 4.74781786106962e-19, 1.1772225574596035e-18, 2.889591149770373e-18, 7.021461510251246e-18, 1.6890089012637188e-17, 4.022070280238714e-17, 9.48157903547322e-17, 2.2127124623349315e-16, 5.111902855003179e-16, 1.1691049518737339e-15, 2.6469010475900543e-15, 5.932465338746881e-15, 1.3162731151670834e-14, 2.8911465762800855e-14, 6.286479553241963e-14, 1.3531882008602697e-13, 2.8835148680350603e-13, 6.082743252881185e-13, 1.2702525461365896e-12, 2.625995396118982e-12, 5.3741668342451615e-12, 1.0887837397262484e-11, 2.1836619471228554e-11, 4.335532874425142e-11, 8.521437421238857e-11, 1.6580458358590643e-10, 3.193695477315732e-10, 6.089810408640702e-10, 1.1495486052366015e-09, 2.1481480193420053e-09, 3.9738764974129935e-09, 7.27742646662481e-09, 1.319333481393963e-08, 2.3677979472626668e-08, 4.20676249520529e-08, 7.398857190757879e-08, 1.2882335164422093e-07, 2.2204338595713047e-07, 3.788736363564433e-07, 6.39976797833875e-07, 1.0701566872444483e-06, 1.7715108153513449e-06, 2.9030435061172303e-06, 4.709519272544368e-06, 7.563327573047441e-06, 1.2024375780027367e-05, 1.8924545919900157e-05, 2.94850380887149e-05, 4.547693808101849e-05, 6.943749378655928e-05, 0.00010495669732889988, 0.0001570505902692841, 0.00023263887421947144, 0.00034114444189664876, 0.0004952307579072902, 0.00071168894230022, 0.00101247923260002, 0.0014259205488438825, 0.0019880066332545526, 0.002743807434250947, 0.0037488902424956307, 0.005070667350661259, 0.0067895472248179775, 0.008999736706509814, 0.0118095158260544, 0.01534078837042205, 0.01972770490282947, 0.025114165092530685, 0.031650037185605745, 0.039485987363558774, 0.04876689194371877, 0.05962390975210613, 0.07216541641028328, 0.08646713928646242, 0.10256197080956149, 0.12043006537870544, 0.13998992617365802, 0.1610912474930448, 0.18351028206203862, 0.20694844077003957, 0.23103469953483863, 0.25533218622946874, 0.27934905925223097, 0.30255348538044763, 0.32439220167745086, 0.34431183278711686, 0.3617818612904054, 0.3763179439532767, 0.38750415498851476, 0.3950127353787847, 0.39862004115367355, 0.39821760809314527, 0.39381756904336157, 0.3855520463090605, 0.3736665615802896, 0.35850792204313137, 0.34050741661169837, 0.32016045794352327, 0.29800400930827603, 0.2745932260807728, 0.25047871677185984, 0.22618569656613793, 0.20219608558255805, 0.17893432004468615, 0.15675732681623833, 0.13594879051917075, 0.11671754532688297, 0.09919967296343765, 0.08346369997605273, 0.06951816883131112, 0.05732080915654202, 0.0467885513258265, 0.03780769343881462, 0.03024364034510724, 0.02394976435149345, 0.018775076803323205, 0.014570534974595997, 0.011193929593162311, 0.00851339809848076, 0.0064096838799737295, 0.004777311696028684, 0.0035248759887838705, 0.0025746452913131025, 0.001861676707255138, 0.001332614158263526, 0.0009443171540943642, 0.0006624370777956696, 0.0004600284428262817, 0.0003162554610820534, 0.000215230929292481, 0.00014500555031307871, 9.671144420245615e-05, 6.385345620962054e-05, 4.173536806384566e-05, 2.7004577332740484e-05, 1.7297519082622216e-05, 1.096840682616814e-05, 6.885200318846564e-06, 4.2786120291436275e-06, 2.632100897727713e-06, 1.6029333198893727e-06, 9.663660803554825e-07, 5.767414920972323e-07, 3.407485476494343e-07, 1.9929670937730613e-07, 1.153930202312381e-07, 6.614122751648698e-08, 3.7529973591539826e-08, 2.108130855032396e-08, 1.1722767954568624e-08, 6.453214040206488e-09, 3.5166995788146016e-09, 1.897176631710412e-09, 1.0131962218816929e-09, 5.35664239925679e-10, 2.803528950926853e-10, 1.4525488061940943e-10, 7.450230683244045e-11, 3.7828751170808954e-11, 1.9014617183781176e-11, 9.46164100876659e-12, 4.660780430507926e-12, 2.2728151691271506e-12, 1.0971926574413598e-12, 5.24342383281561e-13, 2.480620524416489e-13, 1.1617669018352842e-13, 5.3863052773750524e-14, 2.4721580154351614e-14, 1.1232457571901753e-14, 5.052271083536893e-15], \"type\": \"scatter\", \"uid\": \"1318b6bc-6260-4bd6-bfbc-4a01a8cbdcf1\"}, {\"line\": {\"color\": \"rgb(0, 0, 0)\", \"dash\": \"dot\"}, \"mode\": \"lines\", \"name\": \"boundary 1\", \"text\": [\"0.53\"], \"textposition\": \"bottom center\", \"x\": [0.53, 0.53], \"y\": [0, 0.45], \"type\": \"scatter\", \"uid\": \"cd0beeed-8f3e-4ef8-b630-d1114d342b0a\"}, {\"line\": {\"color\": \"rgb(0, 0, 0)\", \"dash\": \"dot\"}, \"mode\": \"lines\", \"name\": \"boundary 2\", \"text\": [\"1.73\"], \"textposition\": \"bottom center\", \"x\": [1.73, 1.73], \"y\": [0, 0.45], \"type\": \"scatter\", \"uid\": \"7f40be15-4e90-429e-9132-ab7f1d1eb481\"}], {\"showlegend\": true, \"title\": \"Likelihood times the prior, for both classes\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"2082498a-bfdc-4923-8971-1a043963628c\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "x = np.linspace(-5,5,200)\n",
    "pi0 = 1             # prior for class 0\n",
    "µ0 = 0; sig0 = 1.5  # mean and variance of the gaussian class conditional density for class 0\n",
    "pi1 = 0.5           # prior for class 1\n",
    "µ1 = 1; sig1 = 0.5  # mean and variance of the gaussian class conditional density for class 1\n",
    "\n",
    "prod0 = (1/(sig0*np.sqrt(2*np.pi))) * np.exp(-(x-µ0)**2/(2*sig0**2)) * pi0  # prod0 = likelihood0 * prior0\n",
    "prod1 = (1/(sig1*np.sqrt(2*np.pi))) * np.exp(-(x-µ1)**2/(2*sig1**2)) * pi1  # prod1 = likelihood1 * prior1\n",
    "\n",
    "line0 = go.Scatter(\n",
    "    x = x,\n",
    "    y = prod0,\n",
    "    name='class 0'\n",
    ")\n",
    "line1 = go.Scatter(\n",
    "    x = x,\n",
    "    y = prod1,\n",
    "    name='class 1'\n",
    ")\n",
    "anno0 = go.Scatter(\n",
    "    x = [0.53, 0.53],\n",
    "    y = [0,     0.45],\n",
    "    mode = 'lines',\n",
    "    textposition='bottom center',\n",
    "    text = ['0.53'],\n",
    "    name = 'boundary 1',\n",
    "    line = dict(color = ('rgb(0, 0, 0)'),\n",
    "        dash = 'dot')\n",
    ")\n",
    "anno1 = go.Scatter(\n",
    "    x = [1.73, 1.73],\n",
    "    y = [0,     0.45],\n",
    "    mode = 'lines',\n",
    "    text = ['1.73'],\n",
    "    name = 'boundary 2',\n",
    "    textposition='bottom center',\n",
    "        line = dict(color = ('rgb(0, 0, 0)'),\n",
    "        dash = 'dot')\n",
    ")\n",
    "layout = go.Layout(title='Likelihood times the prior, for both classes', showlegend=True)\n",
    "data = [line0, line1, anno0, anno1]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    From the chart above, we see that class 1 is the most probable in the interval [0.53, 1.73] ! <br/>\n",
    "    <strong>So for any data x &isin; [0.53, 1.73], class 1 will be predicted by the Bayes classifier! Outside this interval, the predicted class will be 0!</strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,191);\">4) The Plug In Classifier</h1>\n",
    "<p>\n",
    "    Once again, let's recall that we don't know the true distributions: that of the class conditionnal density and that of the prior are  unknown. <strong>So, in practice we use what we call a plug-in classifier: it consists of using the available data to approximate these unknown distributions, and therefore we will no longer be able to say that our classifier is optimal.</strong> (Remember that Bayes Classifier minimizes the prediction error) \n",
    "</p>\n",
    "<br/>\n",
    "<p>\n",
    "    To illustrate this, consider a multiclass classification problem with K classes (K &ge;3), we observe n vectors x<sub>i</sub> (i = 1, ...,n) &isin;  &#8476;<sup>d</sup>. <br/>\n",
    "    We will use Maximum Likelihood Estimation (MLE) to estimate the Bayes Classifier  :<br/>\n",
    "<ul>\n",
    " <li><strong>The prior probability &pi;<sub>y</sub></strong>  that our observation is going to be labelled class y <strong>is the fraction of times that happens in the dataset.</strong> So we just need to sum up the number of times we see class y and divide by the number of observations:<br/>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;\n",
    "    <strong>&pi;<sub>y</sub> = (1/n) &sum;<sub>i&isin;[|1,n|]</sub>  1(y<sub>i</sub>=y)  &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;(E3)</strong>    \n",
    " </li><br/>\n",
    " <li><strong>The class conditionnal densities will also be estimated from the empirical dataset</strong> <br>\n",
    "     Let's consider multivariate Gaussians for each class conditional density, P(x|y) &#8765; N(µ<sub>y</sub>, &Sigma;<sub>y</sub>). <br/>So we need to estimate the mean and the covariance. As for the prior, we will use the MLE: for each class y, we calculate the empirical mean of the data belonging to class y in the dataset, and the empirical covariance of the data belonging to class y in the dataset:<br/><br/>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;\n",
    "     <strong>µ<sub>y</sub> = (1/n<sub>y</sub>) <strong>&sum;</strong><sub>i&isin;[|1,n|]</sub>  1(y<sub>i</sub>=y) x<sub>i</sub>  &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (E4)</strong><br/><br/>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;\n",
    "     \n",
    "   <strong>&Sigma;<sub>y</sub> = (1/n<sub>y</sub>) <strong>&sum;</strong><sub>i&isin;[|1,n|]</sub>  1(y<sub>i</sub>=y) (x<sub>i</sub>-µ<sub>y</sub>) (x<sub>i</sub>-µ<sub>y</sub>)<sup>T</sup>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp; (E5)</strong>  <br/><br/>\n",
    "     \n",
    " </li>\n",
    " \n",
    " <li> As seen before, for any new incoming data x, we take the product of the likelihood and the prior and choose the most probable class, thus the following expression of the Plug-In classifier (under the multivariate gaussian assumption for the class conditionnal densities): <br/><br/> &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;\n",
    "    <strong>f(x) = argmax<sub>y&isin;&upsih;</sub>  &pi;<sub>y</sub> |&Sigma;<sub>y</sub>|<sup>-1/2</sup> exp{ (-1/2) (x-µ<sub>y</sub>)<sup>T</sup> &Sigma;<sub>y</sub><sup>-1</sup> (x-µ<sub>y</sub>) } &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; (E6)</strong> \n",
    " </li>\n",
    " <p>\n",
    "    Let's recall the expression of the probability density of a multivariate gaussian &#8765; f(x|µ, &Sigma;) \n",
    "    <img src=\"multivariateGaussian.JPG\" alt=\"P(x<sub>j</sub>|y) = (1/&sigma;&radic;(2&pi;))exp[-(x-µ)<sup>2</sup>/(2&sigma;<sup>2</sup>)]\">\n",
    "</p>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,191);\">5) Example using the Plug In Classifier</h1>\n",
    "<p>\n",
    "    We would like to determine wheter a given person is a male or a female, based on three features:<br/>\n",
    "<ul>\n",
    "    <li>The height (in feet)</li>\n",
    "    <li>The weight (in lbs)</li>\n",
    "    <li>The foot size (in inches)</li>\n",
    "</ul>\n",
    "Let's consider the following dataset: <br/>\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "\n",
    "<tbody><tr>\n",
    "<th>Person</th>\n",
    "<th>height (feet)</th>\n",
    "<th>weight (lbs)</th>\n",
    "<th>foot size(inches)\n",
    "</th></tr>\n",
    "<tr>\n",
    "<td>male</td>\n",
    "<td>6</td>\n",
    "<td>180</td>\n",
    "<td>12\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>male</td>\n",
    "<td>5.92</td>\n",
    "<td>190</td>\n",
    "<td>11\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>male</td>\n",
    "<td>5.58</td>\n",
    "<td>170</td>\n",
    "<td>12\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>male</td>\n",
    "<td>5.92</td>\n",
    "<td>165</td>\n",
    "<td>10\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>female</td>\n",
    "<td>5</td>\n",
    "<td>100</td>\n",
    "<td>6\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>female</td>\n",
    "<td>5.5</td>\n",
    "<td>150</td>\n",
    "<td>8\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>female</td>\n",
    "<td>5.42</td>\n",
    "<td>130</td>\n",
    "<td>7\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>female</td>\n",
    "<td>5.75</td>\n",
    "<td>150</td>\n",
    "<td>9\n",
    "</td>\n",
    "</tr>\n",
    "    \n",
    "</table>\n",
    "<br/>\n",
    "\n",
    "<p>\n",
    "    Let's apply the formulas given previously to <strong>classify a new sample data of a person 5.8 feet high, 150lbs heavy and whose foot size is 10!</strong>\n",
    "</p>\n",
    "<br/>\n",
    "<p>\n",
    "    We have 2 classes \"male\" and \"female\", this a binary classification problem! <br/><br/>\n",
    "    <strong>First, let's calculate the classes prior probabilities:</strong> <br/>\n",
    "    In the dataset which comprises 8 observations, 4 are labelled male and 4 are labelled female\n",
    "    so we have <br/>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; <strong>(E3) &rArr; &nbsp;&nbsp;&pi;<sub>Male</sub> = &pi;<sub>Female</sub> = 4/8 = 0.5 </strong>\n",
    "</p>    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Under the multivariate Gaussian assumption for the likelihood, <strong>we now have to calculate the mean of each of the 2 classes </strong> \"Male\" and \"Female\",  <br/>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;\n",
    "\n",
    "<strong>(E4) &rArr; &nbsp;&nbsp;µ<sub>Male</sub> = (1/4) (x<sub>1</sub> + x<sub>2</sub> + x<sub>3</sub> + x<sub>4</sub>) </strong><br/><br/></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "µMale = \n",
      "[[  5.855]\n",
      " [176.25 ]\n",
      " [ 11.25 ]]\n"
     ]
    }
   ],
   "source": [
    "piMale = 4/8\n",
    "x1 = np.array([ [6], [180], [12] ])\n",
    "x2 = np.array([ [5.92], [190], [11] ])\n",
    "x3 = np.array([ [5.58], [170], [12] ])\n",
    "x4 = np.array([ [5.92], [165], [10] ])\n",
    "µMale = (x1+x2+x3+x4)/4\n",
    "print( 'µMale = \\n{}'.format(µMale) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;<strong>(E4) &rArr; &nbsp;&nbsp;µ<sub>Female</sub> = (1/4) (x<sub>5</sub> + x<sub>6</sub> + x<sub>7</sub> + x<sub>8</sub>) <br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "µFemale = \n",
      "[[  5.4175]\n",
      " [132.5   ]\n",
      " [  7.5   ]]\n"
     ]
    }
   ],
   "source": [
    "piFemale = 4/8\n",
    "x5 = np.array([ [5], [100], [6] ])\n",
    "x6 = np.array([ [5.5], [150], [8] ])\n",
    "x7 = np.asarray([ [5.42], [130], [7] ])\n",
    "x8 = np.asarray([ [5.75], [150], [9] ])\n",
    "µFemale = (x5+x6+x7+x8)/4\n",
    "print( 'µFemale = \\n{}'.format(µFemale) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Under the multivariate Gaussian assumption for the likelihood, <strong>we now have to calculate the variance of each of the 2 classes</strong> \"Male\" and \"Female\",  <br/>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;\n",
    "   <strong>(E5) &rArr; &nbsp;&nbsp;&Sigma;<sub>Male</sub> = (1/4) [ (x<sub>1</sub>-µ<sub>Male</sub>)(x<sub>1</sub>-µ<sub>Male</sub>)<sup>T</sup> +\n",
    "    (x<sub>2</sub>-µ<sub>Male</sub>)(x<sub>2</sub>-µ<sub>Male</sub>)<sup>T</sup> +\n",
    "    (x<sub>3</sub>-µ<sub>Male</sub>)(x<sub>3</sub>-µ<sub>Male</sub>)<sup>T</sup> +\n",
    "    (x<sub>4</sub>-µ<sub>Male</sub>)(x<sub>4</sub>-µ<sub>Male</sub>)<sup>T</sup> ] </strong><br/>\n",
    "</p>\n",
    "<p> Let's rewrite this in matrix form to ease the notation:<br/>\n",
    "&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;    <strong>&Sigma;<sub>Male</sub> = (1/4) [x<sub>1</sub> x<sub>2</sub> x<sub>3</sub> x<sub>4</sub>) - µ<sub>Male</sub>]   [ (x<sub>1</sub> x<sub>2</sub> x<sub>3</sub> x<sub>4</sub>) - µ<sub>Male</sub> ]<sup>T</sup></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SigmaMale = \n",
      "[[ 2.62750e-02  6.06250e-01 -4.87500e-02]\n",
      " [ 6.06250e-01  9.21875e+01  2.18750e+00]\n",
      " [-4.87500e-02  2.18750e+00  6.87500e-01]]\n"
     ]
    }
   ],
   "source": [
    "SigmaMale = (1/4) * np.dot( np.hstack((x1,x2,x3,x4)) - µMale, (np.hstack((x1,x2,x3,x4)) - µMale).T ) \n",
    "print( 'SigmaMale = \\n{}'.format(SigmaMale) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;    <strong>(E5) &rArr; &Sigma;<sub>Female</sub> = (1/4) [ (x<sub>5</sub>-µ<sub>Female</sub>)(x<sub>5</sub>-µ<sub>Female</sub>)<sup>T</sup> +\n",
    "    (x<sub>6</sub>-µ<sub>Female</sub>)(x<sub>6</sub>-µ<sub>Female</sub>)<sup>T</sup> +\n",
    "    (x<sub>7</sub>-µ<sub>Female</sub>)(x<sub>7</sub>-µ<sub>Female</sub>)<sup>T</sup> +\n",
    "    (x<sub>8</sub>-µ<sub>Female</sub>)(x<sub>8</sub>-µ<sub>Female</sub>)<sup>T</sup> ] </strong><br/>\n",
    "</p>\n",
    "<p> Let's rewrite this in matrix form to ease the notation:<br/>\n",
    "&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;    <strong>&Sigma;<sub>Female</sub> = (1/4) [x<sub>5</sub> x<sub>6</sub> x<sub>7</sub> x<sub>8</sub>) - µ<sub>Female</sub>]   [ (x<sub>5</sub> x<sub>6</sub> x<sub>7</sub> x<sub>8</sub>) - µ<sub>Female</sub> ]<sup>T</sup></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SigmaFemale = \n",
      "[[7.291875e-02 5.206250e+00 2.912500e-01]\n",
      " [5.206250e+00 4.187500e+02 2.125000e+01]\n",
      " [2.912500e-01 2.125000e+01 1.250000e+00]]\n"
     ]
    }
   ],
   "source": [
    "SigmaFemale = (1/4) * np.dot( np.hstack((x5,x6,x7,x8)) - µFemale, (np.hstack((x5,x6,x7,x8)) - µFemale).T ) \n",
    "print( 'SigmaFemale = \\n{}'.format(SigmaFemale) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    We can now calculate the product of the likelihood and the prior for both classes Male and Female, evaluated for the vector x = (6 130 8)<sup>T</sup> :<br/>\n",
    "</p>      \n",
    "<ul> \n",
    "<li>      &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;    <strong>\n",
    "    &pi;<sub>Male</sub> |&Sigma;<sub>Male</sub>|<sup>-1/2</sup> exp{ (-1/2) (x-µ<sub>Male</sub>)<sup>T</sup> &Sigma;<sub>Male</sub><sup>-1</sup> (x-µ<sub>Male</sub>) } </strong> </li> \n",
    "<li>      &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;    <strong>\n",
    "    &pi;<sub>Female</sub> |&Sigma;<sub>Female</sub>|<sup>-1/2</sup> exp{ (-1/2) (x-µ<sub>Female</sub>)<sup>T</sup> &Sigma;<sub>Female</sub><sup>-1</sup> (x-µ<sub>Female</sub>) } </strong> </li>  \n",
    "<ul> \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerator of the posterior probability for x being a Male = 0.008199794869542944\n",
      "Numerator of the posterior probability for x being a Female = 0.00012255000541263892\n",
      "\n",
      "posteriorNumMale > posteriorNumFemale, So the predicted class is Male!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xt = np.array([ [5.8], [150], [10] ])\n",
    "\n",
    "def calcPosteriorNum(x, pi, µ, Sigma):\n",
    "    factor = np.linalg.det(Sigma)**(-1/2)\n",
    "    invSigma = np.linalg.inv(Sigma)\n",
    "    expTerm = (-1/2) * np.dot( np.dot((x - µ).T, invSigma), x - µ )\n",
    "    posteriorNum = factor * np.exp(expTerm) * pi\n",
    "    return posteriorNum[0][0]\n",
    "\n",
    "posteriorNumMale = calcPosteriorNum(xt, piMale, µMale, SigmaMale)\n",
    "print('Numerator of the posterior probability for x being a Male = {}'.format(posteriorNumMale))\n",
    "\n",
    "posteriorNumFemale = calcPosteriorNum(xt, piFemale, µFemale, SigmaFemale)\n",
    "print('Numerator of the posterior probability for x being a Female = {}\\n'.format(posteriorNumFemale))\n",
    "\n",
    "if posteriorNumMale > posteriorNumFemale:\n",
    "    print('posteriorNumMale > posteriorNumFemale, So the predicted class is Male!\\n')\n",
    "else:\n",
    "    print('posteriorNumMale < posteriorNumFemale, So the predicted class is Female!\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<strong>So according to our calculations, the class predicted for our new value x = (5.8 130 8)<sup>T</sup> is Female ! </strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,191);\">6) A more generalist implementation of the Bayes Plug-In Classifier</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pluginClassifier(X_train, y_train, X_test):    \n",
    "    \"\"\"\n",
    "    X_train is a n by d matrix of observations, n is the number of observations, d is the dimension\n",
    "    y_train is a n by 1 numeric vector of the labels\n",
    "    X_test is a m by d matrix of the data to classify, m is the number of observations to classify, d is the dimension\n",
    "    \"\"\"\n",
    "    # 1st, compute the class prior probability\n",
    "    nbClasses = len(np.unique(y_train))\n",
    "    allClasses = range(0,nbClasses)\n",
    "    nTrainObs = X_train.shape[0]   # number of observations in the train set\n",
    "    nTestObs = X_test.shape[0]     # number of observations in the test set\n",
    "    priorProb = []        # probability of the prior \n",
    "    clX  = {}             # dictionnary containing the covariates belonging to a certain class (the key is the class)\n",
    "    muX  = {}             # dictionnary containing the mean of the vectors labelled to a certain class (the key is the class)\n",
    "    varX = {}             # dictionnary containing the variance of the vectors labelled to a certain class (the key is the class)\n",
    "    numPostX = np.ones( (nTestObs, len(allClasses)) )  # numpy array containing the numerator of the posterior probablities\n",
    "    probX = np.ones( (nTestObs, len(allClasses)) )     # numpy array containing the numerator of the posterior probablities    \n",
    "    assignedClass = np.zeros((nTestObs,1),int)             # numpy array containing the assigned classes\n",
    "    for cl in allClasses:\n",
    "        ny = len( y_train[y_train == cl] )\n",
    "        curClassPriorProb =  ny/nTrainObs\n",
    "        priorProb.append(curClassPriorProb)\n",
    "      \n",
    "        # Retrieve the inputs from X_train which belong to class cl\n",
    "        X_train_df = pd.DataFrame(X_train)\n",
    "        clX[cl] = X_train_df[y_train == cl]\n",
    "        # Retrieve the numpy array and transpose it to have a column vector\n",
    "        clX[cl] = np.transpose(clX[cl].values)\n",
    "        assert(ny == clX[cl].shape[1])\n",
    "     \n",
    "        # Compute mean of the inputs which belong to class cl\n",
    "        \n",
    "        muX[cl] = (1/ny) * np.sum( clX[cl], axis=1 )\n",
    "        muX[cl] = (muX[cl]).reshape(X_train.shape[1],1)\n",
    "        assert( muX[cl].shape == (X_train.shape[1],1) )\n",
    "\n",
    "\n",
    "        # Compute variance of theses inputs which belong to class cl\n",
    "        ecart = np.dot( (clX[cl] - muX[cl]), np.transpose(clX[cl] - muX[cl]) )\n",
    "        #print(ecart)\n",
    "        varX[cl] = (1/ny) * ecart\n",
    "        assert(varX[cl].shape[0] == varX[cl].shape[1])\n",
    "        assert(X_train.shape[1] == varX[cl].shape[0])\n",
    "        deter = np.linalg.det(varX[cl])    # determinant of the variance matrix\n",
    "        inversVar = np.linalg.inv(varX[cl])\n",
    "\n",
    "        # Parse the test vector to compute the probability of the Bayes Plug-In classifier\n",
    "        for idx in range(nTestObs) :\n",
    "            curTestObs = np.transpose( [X_test[idx,:]] )  # make it a row vector\n",
    "            expTerm = (-1/2) * np.dot( np.transpose(curTestObs-muX[cl]), np.dot(inversVar, curTestObs-muX[cl]) )\n",
    "            factor = (1/(2*np.pi))**(X_train.shape[1]/2) * (1/np.sqrt(deter)) #\n",
    "            numPostX[idx,cl] =  factor * np.exp(expTerm) * priorProb[cl]\n",
    "\n",
    "    \n",
    "    \n",
    "    # Create Probabilities that sum to 1\n",
    "    for idx in range(nTestObs) :\n",
    "        rescale = 1/np.sum(numPostX[idx,:])\n",
    "        probX[idx,:] = rescale * numPostX[idx,:]\n",
    "        assignedClass[idx] = numPostX[idx,:].tolist().index(max(numPostX[idx,:]))\n",
    "#     probXList = probX.tolist()\n",
    "  \n",
    "    return assignedClass, numPostX, probX\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.transpose(np.hstack((x1,x2,x3,x4,x5,x6,x7,x8)))\n",
    "y_train = np.array([ [0], [0], [0], [0], [1], [1], [1], [1] ])   # 0 is the male class, 1 is the female class\n",
    "X_test = np.transpose(xt)      # make it a row vector\n",
    "assignedClass, numPostX, probX = pluginClassifier(X_train, y_train, X_test) # assuming final_outputs is returned from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class predicted by our plug-in classifier function is Male!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assignedClass[0][0]\n",
    "if assignedClass[0][0] == 0:\n",
    "    print('\\n Class predicted by our plug-in classifier function is Male!\\n')\n",
    "else:\n",
    "    print('\\n Class predicted by our plug-in classifier function is Female!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,191);\">7) The Naïve Bayes Classifier</h1>\n",
    "<p>\n",
    "    We have presented the Bayes classifier which is optimal in the sense that it minimizes the prediction error, but requires the knowledge of the true distribution of the data.\n",
    "</p> \n",
    "<p>\n",
    "As in practice we don't know this distribution, we make an assumption about it and we use the available data to learn the parameters of the chosen distribution, this leads to the Plug-In classifier, which computation is pretty heavy and requires inversing a matrix.\n",
    "</p>\n",
    "<p>\n",
    "    Now can we make a simplifying asumption to ease the calculations? <br/>\n",
    "    The answer is yes, let's suppose that the distribution of the features given the class is independant. \n",
    "    This is called <strong style=\"color:rgb(0,120,191);\">\"Naïve\"</strong> because we're breaking any correlations in the feature, which is a naïve assumption, but in the facts, <strong> it works fairly well!</strong>.\n",
    "</p>\n",
    "<br/>\n",
    "<h3 style=\"color:rgb(0,120,191);\"> Finding the new expresion of our classifier with the Naïve Bayes assumption</h3>\n",
    "<p> For any vector x among our observations, we want to assign the most probable class. <br/><strong>This is done by taking the  argmax<sub>y</sub> P(x|y) P(y) &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;  (E2)</strong> <br/><br/>\n",
    "    x is a vector of d features: x = [x<sub>1</sub> x<sub>2</sub> x<sub>3</sub> ...x<sub>d</sub> ] where <strong   style=\"color:rgb(0,120,191);\"> each x<sub>j</sub> are independant features given the class</strong> (because of the Naïve Bayes assumption)<br/>\n",
    "    <strong>Remember that the product P(x|y) P(y) is equal to the joint probability P(x,y)!</strong> <br/>\n",
    "    <p>\n",
    "&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;        P(x,y) = P(x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>d</sub>, y) <br/>\n",
    "&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;        P(x,y) = P(x<sub>1</sub>|x<sub>2</sub>, ..., x<sub>d</sub>, y)  P(x<sub>2</sub>, ..., x<sub>d</sub>, y) <br/>\n",
    "&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;        P(x,y) = P(x<sub>1</sub>|x<sub>2</sub>, ..., x<sub>d</sub>, y)  P(x<sub>2</sub>|x<sub>3</sub>, ..., x<sub>d</sub>, y) P(x<sub>3</sub>, ..., x<sub>d</sub>, y) <br/>\n",
    "&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;        ... <br/>\n",
    "&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;        P(x,y) = P(x<sub>1</sub>|x<sub>2</sub>, ..., x<sub>d</sub>, y)  P(x<sub>2</sub>|x<sub>3</sub>, ..., x<sub>d</sub>, y) ... P(x<sub>d-1</sub>|x<sub>d</sub>, y) P(x<sub>d</sub>|y)P(y) <br/> <br/>\n",
    "  Now the naïve conditional independance assumption comes into play: we assume that each feature x<sub>j</sub> is conditionally independant of every other feature x<sub>m</sub> <br/>for j &ne; m, given the category y. Then<br/> \n",
    "        &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;        P(x<sub>j</sub>|x<sub>j+1</sub>, x<sub>j+2</sub>, ..., x<sub>d</sub>, y) = P(x<sub>j</sub>|y)   &nbsp; &nbsp;&nbsp; And we can write <br />\n",
    "        &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;        P(x,y) = P(x<sub>1</sub>|y)  P(x<sub>2</sub>|y) ... P(x<sub>d-1</sub>| y) P(x<sub>d</sub>|y) P(y) <br/> \n",
    "        &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;        P(x,y) = P(y) &#928;<sub>j &isin;{1,d}</sub> P(x<sub>j</sub>|y)\n",
    "  </p>\n",
    "    <p>\n",
    "    Eventually, the Naïve Bayes classifier is the function that assings a class label as follows: <br/> &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;    <strong>argmax<sub>y</sub> P(y) &#928;<sub>j &isin;{1,...,d}</sub> P(x<sub>j</sub>|y) &nbsp;&nbsp; (E7)</strong>\n",
    "    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,191);\">8) Naïve Bayes Applied to the gender classification problem</h1>\n",
    "<p>\n",
    "    For our gender classification problem, we have 3 features (x<sub>j</sub>): height, weight and footsize. <br/>\n",
    "    To classify a new sample data of a person 5.8 feet high, 150lbs heavy and whose foot size is 10, we derive from (E7) that we need to calculate the two products:\n",
    "    <ul>\n",
    "        <li>P(Male) P(height|Male) P(weight|Male) P(footsize|Male)</li>\n",
    "        <li>P(Female) P(height|Female) P(weight|Female) P(footsize|Female)</li>\n",
    "</ul>\n",
    "And decide the class of the point as being the most probable!\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "   Remember the dataset: <br/>\n",
    "</p>\n",
    "\n",
    "<table>\n",
    "\n",
    "<tbody><tr>\n",
    "<th>Person</th>\n",
    "<th>height (feet)</th>\n",
    "<th>weight (lbs)</th>\n",
    "<th>foot size(inches)\n",
    "</th></tr>\n",
    "<tr>\n",
    "<td>male</td>\n",
    "<td>6</td>\n",
    "<td>180</td>\n",
    "<td>12\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>male</td>\n",
    "<td>5.92</td>\n",
    "<td>190</td>\n",
    "<td>11\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>male</td>\n",
    "<td>5.58</td>\n",
    "<td>170</td>\n",
    "<td>12\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>male</td>\n",
    "<td>5.92</td>\n",
    "<td>165</td>\n",
    "<td>10\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>female</td>\n",
    "<td>5</td>\n",
    "<td>100</td>\n",
    "<td>6\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>female</td>\n",
    "<td>5.5</td>\n",
    "<td>150</td>\n",
    "<td>8\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>female</td>\n",
    "<td>5.42</td>\n",
    "<td>130</td>\n",
    "<td>7\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>female</td>\n",
    "<td>5.75</td>\n",
    "<td>150</td>\n",
    "<td>9\n",
    "</td>\n",
    "</tr>\n",
    "    \n",
    "</table>\n",
    "<br/>\n",
    "\n",
    "<p>\n",
    "    Let's apply the formulas given previously to classify a new sample data of a person 5.8 feet high, 150lbs heavy and whose foot size is 10!\n",
    "</p>\n",
    "<p>\n",
    "    We have 2 classes \"male\" and \"female\", this a binary classification problem! <br/>\n",
    "    First, let's calculate the classes prior probabilities: <br/>\n",
    "    In the dataset which comprises 8 observations, 4 are labelled male and 4 are labelled female\n",
    "    so we have <br/>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; <strong>&pi;<sub>Male</sub> = &pi;<sub>Female</sub> = 4/8 = 0.5      &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; ( P(Male) = &pi;<sub>Male</sub>  and P(Female) = &pi;<sub>Female</sub> )</strong>\n",
    "</p>    \n",
    "<p>\n",
    "    Then, to estimate the probability densities P(x<sub>j</sub>|y), we can make the assumption they follow univariate gaussian distribution P(x<sub>j</sub>|y) &#8765; f(x|µ, &sigma;<sup>2</sup>) \n",
    "    <img src=\"univariateGaussian.JPG\" alt=\"P(x<sub>j</sub>|y) = (1/&sigma;&radic;(2&pi;))exp[-(x-µ)<sup>2</sup>/(2&sigma;<sup>2</sup>)]\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    So P(height|Male) &#8765; N(µ<sub>0</sub>, &sigma;<sub>0</sub><sup>2</sup>), P(weight|Male)  &#8765; N(µ<sub>1</sub>, &sigma;<sub>1</sub><sup>2</sup>), P(footsize|Male)  &#8765; N(µ<sub>2</sub>, &sigma;<sub>2</sub><sup>2</sup>) <br/><br/>\n",
    "    From the dataset, we can derive µ0 = (6+5.92+5.58+5.92)/4 = 5.855 &nbsp;&nbsp;&nbsp;&nbsp; and &nbsp;&nbsp;&nbsp;&nbsp; &sigma;<sub>0</sub><sup>2</sup> = var(6+5.92+5.58+5.92) &asymp; 0.02675  <br/>\n",
    "    Injecting these values into the equation above leads to P(height|Male)  &asymp; 2.32 <br/>\n",
    "    \n",
    "   <br/> To make our calculations easier, let's define a function to compute the output of the univariate gaussian distribution evaluated in one point\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniGauss(µ, var, x):\n",
    "    pdfx = (1/np.sqrt(2*np.pi*var)) * np.exp( -(x-µ)**2/(2*var) )\n",
    "    return pdfx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<strong>Let's proceed the same way to get the other probabilities:</strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posteriorNumMale = 0.00017756467590579106\n",
      "posteriorNumFemale = 0.00010730313438090195\n",
      "\n",
      "posteriorNumMale > posteriorNumFemale, So our Naïve Bayes Classifier labels our new sample as belonging to the Male class!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the posterior numerator for the Male class\n",
    "l0 = [6, 5.92, 5.58, 5.92]\n",
    "µ0 = np.mean(l0)\n",
    "var0 = np.std(l0)**2\n",
    "pHeightGivenMale = uniGauss(µ0, var0, xt[0][0])\n",
    "\n",
    "l1 = [180, 190, 170, 165]\n",
    "µ1 = np.mean(l1)\n",
    "var1 = np.std(l1)**2\n",
    "pWeightGivenMale = uniGauss(µ1, var1, xt[1][0])\n",
    "\n",
    "l2 = [12, 11, 12, 10]\n",
    "µ2 = np.mean(l2)\n",
    "var2 = np.std(l2)**2\n",
    "pFootSizeGivenMale = uniGauss(µ2, var2, xt[2][0])\n",
    "posteriorNumMale = piMale * pHeightGivenMale * pWeightGivenMale * pFootSizeGivenMale\n",
    "\n",
    "\n",
    "# Calculating the posterior numerator for the Female class\n",
    "l3 = [5, 5.5, 5.42, 5.75]\n",
    "µ3 = np.mean(l3)\n",
    "var3 = np.std(l3)**2\n",
    "pHeightGivenFemale = uniGauss(µ3, var3, xt[0][0])\n",
    "\n",
    "l4 = [100, 150, 130, 150]\n",
    "µ4 = np.mean(l4)\n",
    "var4 = np.std(l4)**2\n",
    "pWeightGivenFemale = uniGauss(µ4, var4, xt[1][0])\n",
    "\n",
    "l5 = [6, 8, 7, 9]\n",
    "µ5 = np.mean(l5)\n",
    "var5 = np.std(l5)**2\n",
    "pFootSizeGivenFemale = uniGauss(µ5, var5, xt[2][0])\n",
    "posteriorNumFemale = piFemale * pHeightGivenFemale * pWeightGivenFemale * pFootSizeGivenFemale\n",
    "\n",
    "print('posteriorNumMale = {}'.format(posteriorNumMale))\n",
    "print('posteriorNumFemale = {}\\n'.format(posteriorNumFemale))\n",
    "\n",
    "if posteriorNumMale > posteriorNumFemale:\n",
    "    print('posteriorNumMale > posteriorNumFemale, So our Naïve Bayes Classifier labels our new sample as belonging to the Male class!\\n')\n",
    "else:\n",
    "    print('posteriorNumMale < posteriorNumFemale, So our Naïve Bayes Classifier labels our new sample as belonging to the Female class!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,191);\">9) Plug-In Bayes Classifier Applied to the iris dataset</h1>\n",
    "<p>\n",
    "    Let's apply our implementation of the Plug-In classifier on the well known \"iris dataset\". <br/> \n",
    " The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.<br/>\n",
    "    The predicted attribute is the class of iris plant. <br/><br/>\n",
    "<strong>Attribute Information:</strong>\n",
    "<ol>       <li>   sepal length in cm </li>\n",
    "<li>   sepal width in cm </li>\n",
    "<li>   petal length in cm </li>\n",
    "<li>   petal width in cm </li>\n",
    "<li>   class:  Iris Setosa, Iris Versicolour, Iris Virginica</li>    \n",
    "</ol>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepalLen    float64\n",
       "sepalWi     float64\n",
       "petalLen    float64\n",
       "petalWi     float64\n",
       "label        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First read the data\n",
    "data = pd.read_csv('iris.data', header=None, names=['sepalLen', 'sepalWi', 'petalLen', 'petalWi','label'], index_col=False )\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepalLen', 'sepalWi', 'petalLen', 'petalWi', 'label', 'target'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function to assign a numeric value to the labels\n",
    "def createNumericClass(inputString):\n",
    "    # for each string assign a numeric label\n",
    "    if inputString == 'Iris-setosa':\n",
    "        val = 0\n",
    "    elif inputString == 'Iris-versicolor':\n",
    "        val = 1\n",
    "    elif inputString == 'Iris-virginica':\n",
    "        val = 2\n",
    "    else:\n",
    "        val = -1\n",
    "    return val\n",
    "\n",
    "data['target'] = data['label'].apply(lambda x: createNumericClass(x))\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.95\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier and predict classes\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataSamp = data.sample(frac=1, random_state=1, axis=0)        # shuffle the dataset \n",
    "propTrain = 0.45                                              # Proportion of data to keep for the training\n",
    "nbSampleTrain = int(propTrain*dataSamp.shape[0])              # Equivalent number of data\n",
    "XTrain = dataSamp.iloc[:nbSampleTrain,:4].values              # Data for the training set (without the labels)\n",
    "yTrain = dataSamp.iloc[:nbSampleTrain,5].values               # Labels for the training set\n",
    "XVal = dataSamp.iloc[nbSampleTrain:,:4].values                # Data for the validation set\n",
    "yVal = dataSamp.iloc[nbSampleTrain:,5].values                 # Labels for the validation set\n",
    "\n",
    "assignedClass, numPostX, probX = pluginClassifier(XTrain, yTrain, XVal)\n",
    "\n",
    "acc = accuracy_score(yVal, assignedClass)\n",
    "print('Accuracy on test set = {:.2f}'.format(acc))\n",
    "A = np.concatenate((yVal.reshape(yVal.shape[0],1), assignedClass), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "mode": "markers",
         "name": "True Class",
         "type": "scatter",
         "uid": "72247a21-c236-4732-9b08-bb77ce4ca586",
         "x": [
          127,
          110,
          65,
          55,
          144,
          138,
          46,
          62,
          74,
          116,
          93,
          100,
          89,
          10,
          34,
          32,
          124,
          38,
          83,
          111,
          149,
          27,
          23,
          67,
          9,
          130,
          97,
          105,
          145,
          87,
          148,
          109,
          64,
          15,
          82,
          41,
          80,
          52,
          26,
          76,
          43,
          24,
          136,
          121,
          143,
          49,
          21,
          70,
          3,
          142,
          30,
          147,
          106,
          47,
          115,
          13,
          88,
          8,
          81,
          60,
          0,
          1,
          57,
          22,
          61,
          63,
          7,
          86,
          96,
          68,
          50,
          101,
          20,
          25,
          134,
          71,
          129,
          79,
          133,
          137,
          72,
          140,
          37
         ],
         "y": [
          2,
          2,
          1,
          1,
          2,
          2,
          0,
          1,
          1,
          2,
          1,
          2,
          1,
          0,
          0,
          0,
          2,
          0,
          1,
          2,
          2,
          0,
          0,
          1,
          0,
          2,
          1,
          2,
          2,
          1,
          2,
          2,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          2,
          2,
          2,
          0,
          0,
          1,
          0,
          2,
          0,
          2,
          2,
          0,
          2,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          2,
          0,
          0,
          2,
          1,
          2,
          1,
          2,
          2,
          1,
          2,
          0
         ]
        },
        {
         "mode": "markers",
         "name": "Plug-In Classifier",
         "type": "scatter",
         "uid": "0d915612-7d3a-438b-9a26-7a1ecb283880",
         "x": [
          127,
          110,
          65,
          55,
          144,
          138,
          46,
          62,
          74,
          116,
          93,
          100,
          89,
          10,
          34,
          32,
          124,
          38,
          83,
          111,
          149,
          27,
          23,
          67,
          9,
          130,
          97,
          105,
          145,
          87,
          148,
          109,
          64,
          15,
          82,
          41,
          80,
          52,
          26,
          76,
          43,
          24,
          136,
          121,
          143,
          49,
          21,
          70,
          3,
          142,
          30,
          147,
          106,
          47,
          115,
          13,
          88,
          8,
          81,
          60,
          0,
          1,
          57,
          22,
          61,
          63,
          7,
          86,
          96,
          68,
          50,
          101,
          20,
          25,
          134,
          71,
          129,
          79,
          133,
          137,
          72,
          140,
          37
         ],
         "y": [
          2,
          2,
          1,
          1,
          2,
          2,
          0,
          1,
          1,
          2,
          1,
          2,
          1,
          0,
          0,
          0,
          2,
          0,
          2,
          2,
          2,
          0,
          0,
          1,
          0,
          2,
          1,
          2,
          2,
          1,
          2,
          2,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          2,
          2,
          2,
          0,
          0,
          1,
          0,
          2,
          0,
          2,
          2,
          0,
          2,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          2,
          1,
          2,
          0,
          0,
          2,
          1,
          2,
          1,
          1,
          2,
          2,
          2,
          0
         ]
        }
       ],
       "layout": {
        "showlegend": true,
        "title": "Iris dataset Validation, Accuracy = 95.2%"
       }
      },
      "text/html": [
       "<div id=\"7d76ef6e-ade7-468d-a9a4-31f20d99990a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7d76ef6e-ade7-468d-a9a4-31f20d99990a\", [{\"mode\": \"markers\", \"name\": \"True Class\", \"x\": [127, 110, 65, 55, 144, 138, 46, 62, 74, 116, 93, 100, 89, 10, 34, 32, 124, 38, 83, 111, 149, 27, 23, 67, 9, 130, 97, 105, 145, 87, 148, 109, 64, 15, 82, 41, 80, 52, 26, 76, 43, 24, 136, 121, 143, 49, 21, 70, 3, 142, 30, 147, 106, 47, 115, 13, 88, 8, 81, 60, 0, 1, 57, 22, 61, 63, 7, 86, 96, 68, 50, 101, 20, 25, 134, 71, 129, 79, 133, 137, 72, 140, 37], \"y\": [2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 2, 1, 2, 0], \"type\": \"scatter\", \"uid\": \"72247a21-c236-4732-9b08-bb77ce4ca586\"}, {\"mode\": \"markers\", \"name\": \"Plug-In Classifier\", \"x\": [127, 110, 65, 55, 144, 138, 46, 62, 74, 116, 93, 100, 89, 10, 34, 32, 124, 38, 83, 111, 149, 27, 23, 67, 9, 130, 97, 105, 145, 87, 148, 109, 64, 15, 82, 41, 80, 52, 26, 76, 43, 24, 136, 121, 143, 49, 21, 70, 3, 142, 30, 147, 106, 47, 115, 13, 88, 8, 81, 60, 0, 1, 57, 22, 61, 63, 7, 86, 96, 68, 50, 101, 20, 25, 134, 71, 129, 79, 133, 137, 72, 140, 37], \"y\": [2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 2, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 2, 1, 1, 2, 2, 2, 0], \"type\": \"scatter\", \"uid\": \"0d915612-7d3a-438b-9a26-7a1ecb283880\"}], {\"showlegend\": true, \"title\": \"Iris dataset Validation, Accuracy = 95.2%\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"7d76ef6e-ade7-468d-a9a4-31f20d99990a\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7d76ef6e-ade7-468d-a9a4-31f20d99990a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7d76ef6e-ade7-468d-a9a4-31f20d99990a\", [{\"mode\": \"markers\", \"name\": \"True Class\", \"x\": [127, 110, 65, 55, 144, 138, 46, 62, 74, 116, 93, 100, 89, 10, 34, 32, 124, 38, 83, 111, 149, 27, 23, 67, 9, 130, 97, 105, 145, 87, 148, 109, 64, 15, 82, 41, 80, 52, 26, 76, 43, 24, 136, 121, 143, 49, 21, 70, 3, 142, 30, 147, 106, 47, 115, 13, 88, 8, 81, 60, 0, 1, 57, 22, 61, 63, 7, 86, 96, 68, 50, 101, 20, 25, 134, 71, 129, 79, 133, 137, 72, 140, 37], \"y\": [2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 2, 1, 2, 0], \"type\": \"scatter\", \"uid\": \"72247a21-c236-4732-9b08-bb77ce4ca586\"}, {\"mode\": \"markers\", \"name\": \"Plug-In Classifier\", \"x\": [127, 110, 65, 55, 144, 138, 46, 62, 74, 116, 93, 100, 89, 10, 34, 32, 124, 38, 83, 111, 149, 27, 23, 67, 9, 130, 97, 105, 145, 87, 148, 109, 64, 15, 82, 41, 80, 52, 26, 76, 43, 24, 136, 121, 143, 49, 21, 70, 3, 142, 30, 147, 106, 47, 115, 13, 88, 8, 81, 60, 0, 1, 57, 22, 61, 63, 7, 86, 96, 68, 50, 101, 20, 25, 134, 71, 129, 79, 133, 137, 72, 140, 37], \"y\": [2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 2, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 2, 1, 1, 2, 2, 2, 0], \"type\": \"scatter\", \"uid\": \"0d915612-7d3a-438b-9a26-7a1ecb283880\"}], {\"showlegend\": true, \"title\": \"Iris dataset Validation, Accuracy = 95.2%\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"7d76ef6e-ade7-468d-a9a4-31f20d99990a\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Classification results on the validation set\n",
    "\n",
    "trueClass = go.Scatter(\n",
    "    x = dataSamp.index[nbSampleTrain:],\n",
    "    y = yVal,\n",
    "    mode = 'markers',\n",
    "    name = 'True Class')\n",
    "\n",
    "plugInPred = go.Scatter(\n",
    "    x = dataSamp.index[nbSampleTrain:],\n",
    "    y = assignedClass.T[0],\n",
    "    mode = 'markers',\n",
    "    name = 'Plug-In Classifier')\n",
    "\n",
    "layout = go.Layout(title='Iris dataset Validation, Accuracy = {:.1f}%'.format(100*acc), showlegend=True)\n",
    "data = [trueClass, plugInPred]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,191);\">10) Naïve Bayes Applied to the iris dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()                                         # Create an instance of the Naïve Bayes classifier\n",
    "clf.fit(XTrain, yTrain)                                    # Train the model\n",
    "NBPred = clf.predict(XVal)                                   # Make predictions\n",
    "accNB = accuracy_score(yVal, NBPred)                         # Compute the accuracy score\n",
    "print('Accuracy on test set = {:.2f}'.format(accNB))       # Print the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "mode": "markers",
         "name": "True Class",
         "type": "scatter",
         "uid": "af333b72-11d7-4c5a-b76d-cbdae6308bb9",
         "x": [
          127,
          110,
          65,
          55,
          144,
          138,
          46,
          62,
          74,
          116,
          93,
          100,
          89,
          10,
          34,
          32,
          124,
          38,
          83,
          111,
          149,
          27,
          23,
          67,
          9,
          130,
          97,
          105,
          145,
          87,
          148,
          109,
          64,
          15,
          82,
          41,
          80,
          52,
          26,
          76,
          43,
          24,
          136,
          121,
          143,
          49,
          21,
          70,
          3,
          142,
          30,
          147,
          106,
          47,
          115,
          13,
          88,
          8,
          81,
          60,
          0,
          1,
          57,
          22,
          61,
          63,
          7,
          86,
          96,
          68,
          50,
          101,
          20,
          25,
          134,
          71,
          129,
          79,
          133,
          137,
          72,
          140,
          37
         ],
         "y": [
          2,
          2,
          1,
          1,
          2,
          2,
          0,
          1,
          1,
          2,
          1,
          2,
          1,
          0,
          0,
          0,
          2,
          0,
          1,
          2,
          2,
          0,
          0,
          1,
          0,
          2,
          1,
          2,
          2,
          1,
          2,
          2,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          2,
          2,
          2,
          0,
          0,
          1,
          0,
          2,
          0,
          2,
          2,
          0,
          2,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          2,
          0,
          0,
          2,
          1,
          2,
          1,
          2,
          2,
          1,
          2,
          0
         ]
        },
        {
         "mode": "markers",
         "name": "Plug-In Classifier",
         "type": "scatter",
         "uid": "ff0e5853-b9b5-499e-8a36-f225bbf88414",
         "x": [
          127,
          110,
          65,
          55,
          144,
          138,
          46,
          62,
          74,
          116,
          93,
          100,
          89,
          10,
          34,
          32,
          124,
          38,
          83,
          111,
          149,
          27,
          23,
          67,
          9,
          130,
          97,
          105,
          145,
          87,
          148,
          109,
          64,
          15,
          82,
          41,
          80,
          52,
          26,
          76,
          43,
          24,
          136,
          121,
          143,
          49,
          21,
          70,
          3,
          142,
          30,
          147,
          106,
          47,
          115,
          13,
          88,
          8,
          81,
          60,
          0,
          1,
          57,
          22,
          61,
          63,
          7,
          86,
          96,
          68,
          50,
          101,
          20,
          25,
          134,
          71,
          129,
          79,
          133,
          137,
          72,
          140,
          37
         ],
         "y": [
          2,
          2,
          1,
          1,
          2,
          2,
          0,
          1,
          1,
          2,
          1,
          2,
          1,
          0,
          0,
          0,
          2,
          0,
          2,
          2,
          2,
          0,
          0,
          1,
          0,
          2,
          1,
          2,
          2,
          1,
          2,
          2,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          2,
          2,
          2,
          0,
          0,
          1,
          0,
          2,
          0,
          2,
          2,
          0,
          2,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          2,
          1,
          2,
          0,
          0,
          2,
          1,
          2,
          1,
          1,
          2,
          2,
          2,
          0
         ]
        },
        {
         "mode": "markers",
         "name": "Naïve Bayes Classifier",
         "type": "scatter",
         "uid": "924c36ae-68e0-424e-bf07-0c9225114911",
         "x": [
          127,
          110,
          65,
          55,
          144,
          138,
          46,
          62,
          74,
          116,
          93,
          100,
          89,
          10,
          34,
          32,
          124,
          38,
          83,
          111,
          149,
          27,
          23,
          67,
          9,
          130,
          97,
          105,
          145,
          87,
          148,
          109,
          64,
          15,
          82,
          41,
          80,
          52,
          26,
          76,
          43,
          24,
          136,
          121,
          143,
          49,
          21,
          70,
          3,
          142,
          30,
          147,
          106,
          47,
          115,
          13,
          88,
          8,
          81,
          60,
          0,
          1,
          57,
          22,
          61,
          63,
          7,
          86,
          96,
          68,
          50,
          101,
          20,
          25,
          134,
          71,
          129,
          79,
          133,
          137,
          72,
          140,
          37
         ],
         "y": [
          2,
          2,
          1,
          1,
          2,
          2,
          0,
          1,
          1,
          2,
          1,
          2,
          1,
          0,
          0,
          0,
          2,
          0,
          1,
          2,
          2,
          0,
          0,
          1,
          0,
          2,
          1,
          2,
          2,
          1,
          2,
          2,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          2,
          2,
          2,
          0,
          0,
          2,
          0,
          2,
          0,
          2,
          1,
          0,
          2,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          2,
          0,
          0,
          1,
          1,
          2,
          1,
          1,
          2,
          1,
          2,
          0
         ]
        }
       ],
       "layout": {
        "showlegend": true,
        "title": "Iris dataset Validation, Accuracy = 95.2%"
       }
      },
      "text/html": [
       "<div id=\"94e9f02e-5276-47c7-b200-2600c994ebf7\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"94e9f02e-5276-47c7-b200-2600c994ebf7\", [{\"mode\": \"markers\", \"name\": \"True Class\", \"x\": [127, 110, 65, 55, 144, 138, 46, 62, 74, 116, 93, 100, 89, 10, 34, 32, 124, 38, 83, 111, 149, 27, 23, 67, 9, 130, 97, 105, 145, 87, 148, 109, 64, 15, 82, 41, 80, 52, 26, 76, 43, 24, 136, 121, 143, 49, 21, 70, 3, 142, 30, 147, 106, 47, 115, 13, 88, 8, 81, 60, 0, 1, 57, 22, 61, 63, 7, 86, 96, 68, 50, 101, 20, 25, 134, 71, 129, 79, 133, 137, 72, 140, 37], \"y\": [2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 2, 1, 2, 0], \"type\": \"scatter\", \"uid\": \"af333b72-11d7-4c5a-b76d-cbdae6308bb9\"}, {\"mode\": \"markers\", \"name\": \"Plug-In Classifier\", \"x\": [127, 110, 65, 55, 144, 138, 46, 62, 74, 116, 93, 100, 89, 10, 34, 32, 124, 38, 83, 111, 149, 27, 23, 67, 9, 130, 97, 105, 145, 87, 148, 109, 64, 15, 82, 41, 80, 52, 26, 76, 43, 24, 136, 121, 143, 49, 21, 70, 3, 142, 30, 147, 106, 47, 115, 13, 88, 8, 81, 60, 0, 1, 57, 22, 61, 63, 7, 86, 96, 68, 50, 101, 20, 25, 134, 71, 129, 79, 133, 137, 72, 140, 37], \"y\": [2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 2, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 2, 1, 1, 2, 2, 2, 0], \"type\": \"scatter\", \"uid\": \"ff0e5853-b9b5-499e-8a36-f225bbf88414\"}, {\"mode\": \"markers\", \"name\": \"Na\\u00efve Bayes Classifier\", \"x\": [127, 110, 65, 55, 144, 138, 46, 62, 74, 116, 93, 100, 89, 10, 34, 32, 124, 38, 83, 111, 149, 27, 23, 67, 9, 130, 97, 105, 145, 87, 148, 109, 64, 15, 82, 41, 80, 52, 26, 76, 43, 24, 136, 121, 143, 49, 21, 70, 3, 142, 30, 147, 106, 47, 115, 13, 88, 8, 81, 60, 0, 1, 57, 22, 61, 63, 7, 86, 96, 68, 50, 101, 20, 25, 134, 71, 129, 79, 133, 137, 72, 140, 37], \"y\": [2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 2, 1, 1, 2, 1, 2, 0], \"type\": \"scatter\", \"uid\": \"924c36ae-68e0-424e-bf07-0c9225114911\"}], {\"showlegend\": true, \"title\": \"Iris dataset Validation, Accuracy = 95.2%\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"94e9f02e-5276-47c7-b200-2600c994ebf7\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"94e9f02e-5276-47c7-b200-2600c994ebf7\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"94e9f02e-5276-47c7-b200-2600c994ebf7\", [{\"mode\": \"markers\", \"name\": \"True Class\", \"x\": [127, 110, 65, 55, 144, 138, 46, 62, 74, 116, 93, 100, 89, 10, 34, 32, 124, 38, 83, 111, 149, 27, 23, 67, 9, 130, 97, 105, 145, 87, 148, 109, 64, 15, 82, 41, 80, 52, 26, 76, 43, 24, 136, 121, 143, 49, 21, 70, 3, 142, 30, 147, 106, 47, 115, 13, 88, 8, 81, 60, 0, 1, 57, 22, 61, 63, 7, 86, 96, 68, 50, 101, 20, 25, 134, 71, 129, 79, 133, 137, 72, 140, 37], \"y\": [2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 2, 1, 2, 0], \"type\": \"scatter\", \"uid\": \"af333b72-11d7-4c5a-b76d-cbdae6308bb9\"}, {\"mode\": \"markers\", \"name\": \"Plug-In Classifier\", \"x\": [127, 110, 65, 55, 144, 138, 46, 62, 74, 116, 93, 100, 89, 10, 34, 32, 124, 38, 83, 111, 149, 27, 23, 67, 9, 130, 97, 105, 145, 87, 148, 109, 64, 15, 82, 41, 80, 52, 26, 76, 43, 24, 136, 121, 143, 49, 21, 70, 3, 142, 30, 147, 106, 47, 115, 13, 88, 8, 81, 60, 0, 1, 57, 22, 61, 63, 7, 86, 96, 68, 50, 101, 20, 25, 134, 71, 129, 79, 133, 137, 72, 140, 37], \"y\": [2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 2, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 2, 1, 1, 2, 2, 2, 0], \"type\": \"scatter\", \"uid\": \"ff0e5853-b9b5-499e-8a36-f225bbf88414\"}, {\"mode\": \"markers\", \"name\": \"Na\\u00efve Bayes Classifier\", \"x\": [127, 110, 65, 55, 144, 138, 46, 62, 74, 116, 93, 100, 89, 10, 34, 32, 124, 38, 83, 111, 149, 27, 23, 67, 9, 130, 97, 105, 145, 87, 148, 109, 64, 15, 82, 41, 80, 52, 26, 76, 43, 24, 136, 121, 143, 49, 21, 70, 3, 142, 30, 147, 106, 47, 115, 13, 88, 8, 81, 60, 0, 1, 57, 22, 61, 63, 7, 86, 96, 68, 50, 101, 20, 25, 134, 71, 129, 79, 133, 137, 72, 140, 37], \"y\": [2, 2, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 2, 1, 1, 2, 1, 2, 0], \"type\": \"scatter\", \"uid\": \"924c36ae-68e0-424e-bf07-0c9225114911\"}], {\"showlegend\": true, \"title\": \"Iris dataset Validation, Accuracy = 95.2%\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"94e9f02e-5276-47c7-b200-2600c994ebf7\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Classification results on the validation set\n",
    "\n",
    "NaiveBayesPred = go.Scatter(\n",
    "    x = dataSamp.index[nbSampleTrain:],\n",
    "    y = NBPred,\n",
    "    mode = 'markers',\n",
    "    name = 'Naïve Bayes Classifier')\n",
    "\n",
    "layout = go.Layout(title='Iris dataset Validation, Accuracy = {:.1f}%'.format(100*acc), showlegend=True)\n",
    "data = [trueClass, plugInPred, NaiveBayesPred]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,191);\">11) Conclusion</h1>\n",
    "<p>\n",
    "    Through this tutorial, we explored the Bayes classifier, the plug-in classifier and the Naïve Bayes classifier. <br/>\n",
    "  <ul>\n",
    "     <li>    We gave proper definition of each of these classifiers and played with a toy example regarding gender classification.</li>\n",
    "     <li>We also derived our own implementation of the plug-in classifier</li>\n",
    "     <li>We enventually achieved a fairly reasonnable accuracy of 95% during the validation step on the iris dataset</li>\n",
    "    </ul>   \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    Following ressources were used to build this tutorial:\n",
    "    <ul>\n",
    "        <li><a href=\"https://web.stanford.edu/~hastie/Papers/ESLII.pdf\">The elements of statistical learning</a></li>\n",
    "        <li><a href=\"https://www.edx.org/course/machine-learning\">Columbia Machine Learning Course</a></li>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">Gender classification exemple</a></li>\n",
    "        <li><a href=\"https://archive.ics.uci.edu/ml/datasets/Iris/\">UCI Machine Learning Repository</a></li>\n",
    "    </ul>\n",
    "</p>\n",
    "<br/>\n",
    "<p>\n",
    "Author: Chamsdine SADIKOU <br/>\n",
    "Company: CS CONTROLCOM    <br/>\n",
    "Version: 1.0.0    \n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
